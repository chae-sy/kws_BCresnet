{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4523eb1c-2c49-4bcc-b241-79505cf6df40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:58:31.116056Z",
     "iopub.status.busy": "2024-09-01T06:58:31.115054Z",
     "iopub.status.idle": "2024-09-01T06:58:45.842613Z",
     "shell.execute_reply": "2024-09-01T06:58:45.841610Z",
     "shell.execute_reply.started": "2024-09-01T06:58:31.116056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c933b02-15e4-4485-9771-ce7fde1d578b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:58:48.046392Z",
     "iopub.status.busy": "2024-09-01T06:58:48.045388Z",
     "iopub.status.idle": "2024-09-01T06:58:51.317733Z",
     "shell.execute_reply": "2024-09-01T06:58:51.315729Z",
     "shell.execute_reply.started": "2024-09-01T06:58:48.046392Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cc87c2-847b-4a0b-b2f0-61316dae8e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:58:58.669218Z",
     "iopub.status.busy": "2024-09-01T06:58:58.666219Z",
     "iopub.status.idle": "2024-09-01T06:58:58.680048Z",
     "shell.execute_reply": "2024-09-01T06:58:58.677852Z",
     "shell.execute_reply.started": "2024-09-01T06:58:58.669218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c11bd9f-71ad-4de8-9f6e-ee2772b6778e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:59:01.249922Z",
     "iopub.status.busy": "2024-09-01T06:59:01.248922Z",
     "iopub.status.idle": "2024-09-01T06:59:01.280125Z",
     "shell.execute_reply": "2024-09-01T06:59:01.279122Z",
     "shell.execute_reply.started": "2024-09-01T06:59:01.249922Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset 나누기\n",
    "\n",
    "import os\n",
    "import random\n",
    "#random.seed(10)\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, dataset_path, keywords, subset, unknown_label, sample_ratio=0.2, noise_label='_background_noise_', num_noise_samples=100):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.keywords = keywords\n",
    "        self.unknown_label = unknown_label\n",
    "        self.noise_label = noise_label\n",
    "        self.num_noise_samples = num_noise_samples\n",
    "        self.all_classes =self.unknown_label+ self.keywords +  [self.noise_label]\n",
    "        self.subset = subset\n",
    "        self.sample_ratio = sample_ratio\n",
    "\n",
    "        self.keywords_to_index=['unknown']+self.keywords+[self.noise_label]\n",
    "        \n",
    "        \n",
    "        # Load lists for validation and test datasets\n",
    "        self.validation_list = self._load_file_list(os.path.join(dataset_path, 'validation_list.txt'))\n",
    "        self.testing_list = self._load_file_list(os.path.join(dataset_path, 'testing_list.txt'))\n",
    "\n",
    "        self.audio_files = []\n",
    "        self.labels = []\n",
    "        self.background_noises = []\n",
    "        unknown_files = []\n",
    "\n",
    "        # Load all audio files and corresponding labels\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            label = os.path.basename(root)\n",
    "            if label in self.all_classes:\n",
    "                for file in files:\n",
    "                    if file.endswith('.wav'):\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        file_path = r\"{}\".format(file_path)\n",
    "                        if label == noise_label: #noise append -> (txt에 있으면) unknown에 append + (txt에 있으면) audio_file에 append\n",
    "                            self.background_noises.append(file_path)\n",
    "                        else:\n",
    "                            if label not in self.keywords: #지정 keyword (10개) 중 없는 경우 -> unknown 할당\n",
    "                                label = 'unknown'\n",
    "                                if self._is_in_subset(file_path):\n",
    "                                    unknown_files.append((file_path, label))\n",
    "                            else: \n",
    "                                if self._is_in_subset(file_path):\n",
    "                                    self.audio_files.append(file_path)\n",
    "                                    self.labels.append(label)\n",
    "\n",
    "        # unknown class data를 sample_ratio(default=0.2) 비율로 sampling\n",
    "        if unknown_files:\n",
    "            total_desired_unknowns = int((len(self.audio_files) / (1 - self.sample_ratio)) * self.sample_ratio)\n",
    "            if total_desired_unknowns < len(unknown_files):\n",
    "                unknown_files = random.sample(unknown_files, total_desired_unknowns)\n",
    "\n",
    "        # Add the sampled unknown files to the dataset\n",
    "        for file_path, label in unknown_files:\n",
    "            self.audio_files.append(file_path)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        # Generate random slices of background noise\n",
    "        self.noise_samples = []\n",
    "        for _ in range(num_noise_samples):\n",
    "            noise_path = random.choice(self.background_noises)\n",
    "            waveform, sample_rate = torchaudio.load(noise_path)\n",
    "            max_offset = waveform.size(1) - sample_rate\n",
    "            offset = random.randint(0, max_offset)\n",
    "            noise_slice = waveform[:, offset:offset + sample_rate]\n",
    "            self.noise_samples.append(noise_slice)\n",
    "\n",
    "    def _load_file_list(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_list = f.read().splitlines()\n",
    "        return set(file_list)\n",
    "\n",
    "    def _is_in_subset(self, file_path):\n",
    "        relative_path = os.path.relpath(file_path, self.dataset_path)\n",
    "        relative_path = relative_path.replace('\\\\', '/')\n",
    "        if self.subset == 'train':\n",
    "            return relative_path not in self.validation_list and relative_path not in self.testing_list\n",
    "        elif self.subset == 'validation':\n",
    "            return relative_path in self.validation_list\n",
    "        elif self.subset == 'test':\n",
    "            return relative_path in self.testing_list\n",
    "        else:\n",
    "            raise ValueError(\"Subset must be one of ['train', 'validation', 'test']\")\n",
    "\n",
    "    def _pad_waveform(self, waveform, target_length=16000):\n",
    "      current_length = waveform.shape[1]\n",
    "      if current_length < target_length:\n",
    "        pad_amount = target_length - current_length\n",
    "        padding = torch.zeros((waveform.shape[0], pad_amount))  # (channels, pad_amount)\n",
    "        waveform = torch.cat((waveform, padding), dim=1)\n",
    "      return waveform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files) + self.num_noise_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        #classes=self.all_classes ## to be fixed\n",
    "        if idx < len(self.audio_files):\n",
    "            file_path = self.audio_files[idx]\n",
    "            label = self.labels[idx]\n",
    "            label_index=self.keywords_to_index.index(label) # label to index\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            waveform=self._pad_waveform(waveform) #padding\n",
    "            filename = os.path.basename(file_path)\n",
    "            speaker_id, utterance_number=tuple(filename.split('_nohash_'))\n",
    "            utterance_number=utterance_number.split('.')[0]\n",
    "        else:\n",
    "            noise_idx = idx - len(self.audio_files)\n",
    "            waveform = self.noise_samples[noise_idx-1]\n",
    "            sample_rate = waveform.shape[1]\n",
    "            label = self.noise_label\n",
    "            label_index=self.keywords_to_index.index(label) # label to index\n",
    "            speaker_id= None\n",
    "            utterance_number=None\n",
    "\n",
    "        return waveform, sample_rate, label_index, speaker_id, utterance_number\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc0ce96-d963-45d8-b8c7-95c0b5610d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T08:21:07.658854Z",
     "iopub.status.busy": "2024-08-27T08:21:07.656639Z",
     "iopub.status.idle": "2024-08-27T08:21:16.956727Z",
     "shell.execute_reply": "2024-08-27T08:21:16.955430Z",
     "shell.execute_reply.started": "2024-08-27T08:21:07.658854Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "\n",
    "dataset = SPEECHCOMMANDS(root=\"./\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c850f48-a6e5-47c8-aabe-e8954cc22c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:59:05.599408Z",
     "iopub.status.busy": "2024-09-01T06:59:05.597365Z",
     "iopub.status.idle": "2024-09-01T06:59:56.888239Z",
     "shell.execute_reply": "2024-09-01T06:59:56.793398Z",
     "shell.execute_reply.started": "2024-09-01T06:59:05.599408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Usage\n",
    "dataset_path = r'SpeechCommands\\speech_commands_v0.02'\n",
    "unknown_label='backward, bed, bird, cat, dog, eight, five, follow, forward, four, happy, house, learn, marvin, nine, one, seven, sheila, six, three, tree, two, visual, wow, zero'.split(', ')\n",
    "keywords = 'yes, no, up, down, left, right, on, off, stop, go'.split(', ')\n",
    "num_noise_samples = 2000\n",
    "\n",
    "if (len(unknown_label)+len(keywords)==35): #unknown과 keyword가 합쳐서 35개 되는지 확인\n",
    "  # Train dataset\n",
    "  train_set = SpeechCommandsDataset(dataset_path, keywords, unknown_label=unknown_label, subset='train', num_noise_samples=num_noise_samples)\n",
    "\n",
    "  # Validation dataset\n",
    "  #val_set = SpeechCommandsDataset(dataset_path, keywords, unknown_label=unknown_label, subset='validation', num_noise_samples=num_noise_samples)\n",
    "\n",
    "  # Test dataset\n",
    "  test_set = SpeechCommandsDataset(dataset_path, keywords, unknown_label=unknown_label, subset='test', num_noise_samples=num_noise_samples)\n",
    "else: print(\"Error\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd04fca-1420-4d5f-ab7b-4b5bc54931c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:00:01.419361Z",
     "iopub.status.busy": "2024-09-01T07:00:01.418360Z",
     "iopub.status.idle": "2024-09-01T07:00:01.488701Z",
     "shell.execute_reply": "2024-09-01T07:00:01.487696Z",
     "shell.execute_reply.started": "2024-09-01T07:00:01.419361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set 개수 : 40461, test_set 개수 : 7092\n"
     ]
    }
   ],
   "source": [
    "print(\"train_set 개수 : {:}, test_set 개수 : {:}\".format(len(train_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae16993-a9f6-49a3-942d-81ec19060568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T02:16:47.005965Z",
     "iopub.status.busy": "2024-08-30T02:16:47.005965Z",
     "iopub.status.idle": "2024-08-30T02:17:03.243215Z",
     "shell.execute_reply": "2024-08-30T02:17:03.242206Z",
     "shell.execute_reply.started": "2024-08-30T02:16:47.005965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0, Count: 1018\n",
      "Label: 1, Count: 419\n",
      "Label: 2, Count: 405\n",
      "Label: 3, Count: 425\n",
      "Label: 4, Count: 406\n",
      "Label: 5, Count: 412\n",
      "Label: 6, Count: 396\n",
      "Label: 7, Count: 396\n",
      "Label: 8, Count: 402\n",
      "Label: 9, Count: 411\n",
      "Label: 10, Count: 402\n",
      "Label: 11, Count: 2001\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_list = []\n",
    "for _, _, label, _, _ in test_set:\n",
    "    label_list.append(label)\n",
    "\n",
    "label_counts = Counter(label_list)\n",
    "\n",
    "# 라벨과 개수 오름차순으로 출력\n",
    "for label in sorted(label_counts.keys()):\n",
    "    print(f\"Label: {label}, Count: {label_counts[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d48c280-d6b4-4c90-8f3d-ee1c46ad90e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:00:05.538468Z",
     "iopub.status.busy": "2024-09-01T07:00:05.537466Z",
     "iopub.status.idle": "2024-09-01T07:00:06.978705Z",
     "shell.execute_reply": "2024-09-01T07:00:06.977700Z",
     "shell.execute_reply.started": "2024-09-01T07:00:05.538468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\n",
      "Sample rate of waveform: 16000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "plt.plot(waveform.t().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7b9107-ec23-4e87-803c-6e142aaf5515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:00:45.404077Z",
     "iopub.status.busy": "2024-09-01T07:00:45.403103Z",
     "iopub.status.idle": "2024-09-01T07:00:47.000268Z",
     "shell.execute_reply": "2024-09-01T07:00:46.999182Z",
     "shell.execute_reply.started": "2024-09-01T07:00:45.404077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of spectrogram: torch.Size([19, 29])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spectrogram 변환\n",
    "def sp_transform(waveform):\n",
    "\n",
    "  waveform = waveform.cpu()\n",
    "\n",
    "  spectrogram_transform = torchaudio.transforms.MelSpectrogram(sample_rate = 16000, win_length = 1024, n_fft = 1024, hop_length = 534, n_mels = 19, center=False)\n",
    "  spectrogram = spectrogram_transform(waveform)\n",
    "  epsilon = 1e-6\n",
    "  spectrogram = spectrogram + epsilon\n",
    "  spectrogram = spectrogram.log2()\n",
    "\n",
    "  spectrogram = spectrogram.to(device)\n",
    "  return spectrogram\n",
    "\n",
    "sp = sp_transform(waveform)[0]\n",
    "plt.imshow(sp.cpu().numpy(), aspect='auto')\n",
    "print(\"size of spectrogram: {:}\".format(sp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28f38e0-8315-42f0-8c8a-8eb7bc722e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:01:45.930375Z",
     "iopub.status.busy": "2024-09-01T07:01:45.929375Z",
     "iopub.status.idle": "2024-09-01T07:01:45.946778Z",
     "shell.execute_reply": "2024-09-01T07:01:45.945774Z",
     "shell.execute_reply.started": "2024-09-01T07:01:45.930375Z"
    }
   },
   "outputs": [],
   "source": [
    "#데이터 길이 맞춰주기 위해 padding\n",
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "# data중 waveform, label(index로 된)를 각각 tensor, target에 추가\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.tensor(targets)\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "# train, test 위한 data batch_size로 나눔\n",
    "batch_size = 128\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d84d37-d216-4438-9312-c8bc8ef8b04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:01:49.673228Z",
     "iopub.status.busy": "2024-09-01T07:01:49.672256Z",
     "iopub.status.idle": "2024-09-01T07:01:49.734365Z",
     "shell.execute_reply": "2024-09-01T07:01:49.732362Z",
     "shell.execute_reply.started": "2024-09-01T07:01:49.673228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2023 Qualcomm Technologies, Inc.\n",
    "# All Rights Reserved.\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_plane,\n",
    "        out_plane,\n",
    "        idx,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        groups=1,\n",
    "        use_dilation=False,\n",
    "        activation=True,\n",
    "        swish=False,\n",
    "        BN=True,\n",
    "        ssn=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        def get_padding(kernel_size, use_dilation):\n",
    "            rate = 1  # dilation rate\n",
    "            padding_len = (kernel_size - 1) // 2\n",
    "            if use_dilation and kernel_size > 1:\n",
    "                rate = int(2**self.idx)\n",
    "                padding_len = rate * padding_len\n",
    "            return padding_len, rate\n",
    "\n",
    "        self.idx = idx\n",
    "\n",
    "        # padding and dilation rate\n",
    "        if isinstance(kernel_size, (list, tuple)):\n",
    "            padding = []\n",
    "            rate = []\n",
    "            for k_size in kernel_size:\n",
    "                temp_padding, temp_rate = get_padding(k_size, use_dilation)\n",
    "                rate.append(temp_rate)\n",
    "                padding.append(temp_padding)\n",
    "        else:\n",
    "            padding, rate = get_padding(kernel_size, use_dilation)\n",
    "\n",
    "        #convbnrelu block\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_plane, out_plane, kernel_size, stride, (0,0), rate, groups, bias=False)\n",
    "        )\n",
    "        if ssn:\n",
    "            if idx==0:\n",
    "                layers.append(SubSpectralNorm(out_plane, spec_groups=4))\n",
    "            elif idx==1:\n",
    "                layers.append(SubSpectralNorm(out_plane, spec_groups=3))\n",
    "            elif idx==2:\n",
    "                layers.append(SubSpectralNorm(out_plane, spec_groups=1))\n",
    "        elif BN:\n",
    "            layers.append(nn.BatchNorm2d(out_plane))\n",
    "        if swish:\n",
    "            layers.append(nn.SiLU(True))\n",
    "        elif activation:\n",
    "            layers.append(nn.ReLU6(True))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class BCResBlock(nn.Module):\n",
    "    def __init__(self, in_plane, out_plane, idx, stride):\n",
    "        super().__init__()\n",
    "        self.transition_block = in_plane != out_plane\n",
    "        kernel_size = (3, 3)\n",
    "\n",
    "        # 2D part (f2)\n",
    "        layers = []\n",
    "        if self.transition_block:\n",
    "            layers.append(ConvBNReLU(in_plane, out_plane, idx, 1, 1))\n",
    "            in_plane = out_plane\n",
    "        layers.append(\n",
    "            ConvBNReLU(\n",
    "                in_plane,\n",
    "                out_plane,\n",
    "                idx,\n",
    "                (kernel_size[0], 1),\n",
    "                (2, 1),\n",
    "                groups=in_plane,\n",
    "                use_dilation=False,\n",
    "                ssn=True, # modified\n",
    "                activation=False,\n",
    "            )\n",
    "        )\n",
    "        self.f2 = nn.Sequential(*layers)\n",
    "        self.avg_gpool = nn.AdaptiveAvgPool2d((1, 29))\n",
    "\n",
    "        # 1D part (f1)\n",
    "        self.f1 = nn.Sequential(\n",
    "            ConvBNReLU(\n",
    "                out_plane,\n",
    "                out_plane,\n",
    "                idx,\n",
    "                (1, kernel_size[1]),\n",
    "                (1, 1),\n",
    "                groups=out_plane,\n",
    "                swish=False,\n",
    "                use_dilation=False,\n",
    "            ),\n",
    "            nn.Conv2d(out_plane, out_plane, 1, bias=False), # is this necessary?\n",
    "            nn.Dropout2d(0.1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2D part\n",
    "        shortcut = x\n",
    "        x = self.f2(x)\n",
    "        aux_2d_res = x\n",
    "        x = self.avg_gpool(x)\n",
    "\n",
    "        # 1D part\n",
    "        x = self.f1(x)\n",
    "        x = x + aux_2d_res\n",
    "        if not self.transition_block:\n",
    "            x = x + shortcut\n",
    "        x = F.relu6(x, True)\n",
    "        return x\n",
    "\n",
    "\n",
    "def BCBlockStage(num_layers, last_channel, cur_channel, idx, use_stride):\n",
    "    stage = nn.ModuleList()\n",
    "    channels = [last_channel] + [cur_channel] * num_layers\n",
    "    for i in range(num_layers):\n",
    "        stride = (2, 1) if use_stride and i == 0 else (1, 1)\n",
    "        stage.append(BCResBlock(channels[i], channels[i + 1], idx, stride))\n",
    "    return stage\n",
    "\n",
    "\n",
    "class BCResNets(nn.Module):\n",
    "    def __init__(self, base_c, num_classes=12):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.n = [1, 1, 1]  # identical modules repeated n times\n",
    "        self.c = [\n",
    "            int(base_c * 2),\n",
    "            base_c,\n",
    "            int(base_c * 2),\n",
    "            base_c * 3,\n",
    "            #int(base_c * 2.5),\n",
    "            base_c * 4,\n",
    "        ]  # num channels\n",
    "        self.s = []  # stage using stride\n",
    "        self._build_network()\n",
    "        \n",
    "\n",
    "\n",
    "    def _build_network(self):\n",
    "        # Head: (Conv-BN-ReLU)\n",
    "        self.cnn_head = nn.Sequential(\n",
    "            nn.Conv2d(1, self.c[0], 3, (1, 1), 0, bias=False), #padding=2\n",
    "            nn.BatchNorm2d(self.c[0]),\n",
    "            nn.ReLU6(True),\n",
    "        )\n",
    "        # Body: BC-ResBlocks\n",
    "        self.BCBlocks = nn.ModuleList([])\n",
    "        for idx, n in enumerate(self.n):\n",
    "            use_stride = idx in self.s\n",
    "            self.BCBlocks.append(BCBlockStage(n, self.c[idx], self.c[idx + 1], idx, use_stride))\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Conv2d(\n",
    "            #    self.c[-2], self.c[-2], (5, 5), bias=False, groups=self.c[-2], padding=(0, 2)\n",
    "            #),\n",
    "            #nn.Conv2d(self.c[-2], self.c[-1], 1, bias=False),\n",
    "            #nn.BatchNorm2d(self.c[-1]),\n",
    "            #nn.ReLU6(True),\n",
    "            #nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            #nn.Conv2d(self.c[-1], self.num_classes, 1),\n",
    "\n",
    "            #nn.Conv2d(self.c[-2], self.c[-1], kernel_size=1),\n",
    "            nn.BatchNorm2d(self.c[-2]),\n",
    "            nn.Conv2d(self.c[-2], self.num_classes, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_head(x)\n",
    "        for i, num_modules in enumerate(self.n):\n",
    "            for j in range(num_modules):\n",
    "                x = self.BCBlocks[i][j](x)\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(-1, x.shape[1])\n",
    "        return x\n",
    "\n",
    "class SubSpectralNorm(nn.Module):\n",
    "    def __init__(self, num_features, spec_groups=16, affine=\"Sub\", batch=True, dim=2):\n",
    "        super().__init__()\n",
    "        self.spec_groups = spec_groups\n",
    "        self.affine_all = False\n",
    "        affine_norm = False\n",
    "        if (\n",
    "            affine == \"Sub\"\n",
    "        ):  # affine transform for each sub group. use affine of torch implementation\n",
    "            affine_norm = True\n",
    "        elif affine == \"All\":\n",
    "            self.affine_all = True\n",
    "            self.weight = nn.Parameter(torch.ones((1, num_features, 1, 1)))\n",
    "            self.bias = nn.Parameter(torch.zeros((1, num_features, 1, 1)))\n",
    "        if batch:\n",
    "            self.ssnorm = nn.BatchNorm2d(num_features * spec_groups, affine=affine_norm)\n",
    "        else:\n",
    "            self.ssnorm = nn.InstanceNorm2d(num_features * spec_groups, affine=affine_norm)\n",
    "        self.sub_dim = dim\n",
    "\n",
    "    def forward(self, x):  # when dim h is frequency dimension\n",
    "        if self.sub_dim in (3, -1):\n",
    "            x = x.transpose(2, 3)\n",
    "            x = x.contiguous()\n",
    "        b, c, h, w = x.size()\n",
    "        assert h % self.spec_groups == 0\n",
    "        x = x.contiguous().view(b, c * self.spec_groups, h // self.spec_groups, w) \n",
    "        x = self.ssnorm(x)\n",
    "        x = x.contiguous().view(b, c, h, w)\n",
    "        if self.affine_all:\n",
    "            x = x * self.weight + self.bias\n",
    "        if self.sub_dim in (3, -1):\n",
    "            x = x.transpose(2, 3)\n",
    "            x = x.contiguous()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cccd94bd-627e-4f10-a09b-b0be5cadfd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T02:43:33.262024Z",
     "iopub.status.busy": "2024-08-30T02:43:33.261050Z",
     "iopub.status.idle": "2024-08-30T02:43:34.478292Z",
     "shell.execute_reply": "2024-08-30T02:43:34.477287Z",
     "shell.execute_reply.started": "2024-08-30T02:43:33.262024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCResNets(\n",
       "  (cnn_head): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (BCBlocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(3, 1), stride=(2, 1), groups=8, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), groups=8, bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(2, 1), groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 1), stride=(2, 1), groups=24, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), groups=24, bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_kw=len(keywords)\n",
    "model=BCResNets(base_c=8, num_classes=num_kw+2)\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f576ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU6'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "number of MACs: 323999.0, number of parameters: 2748.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "input = torch.randn(1, 1, 19, 29).to(device)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "print(\"number of MACs: {:}, number of parameters: {:}\".format(macs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095d3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing the attributes after using thop (total_ops, total_params)\n",
    "\n",
    "for layer in model.modules():\n",
    "    if hasattr(layer, 'total_ops'):\n",
    "        del layer.total_ops\n",
    "    if hasattr(layer, 'total_params'):\n",
    "        del layer.total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3dee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCResNets(\n",
      "  (cnn_head): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (BCBlocks): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): BCResBlock(\n",
      "        (f2): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(8, 8, kernel_size=(3, 1), stride=(2, 1), groups=8, bias=False)\n",
      "              (1): SubSpectralNorm(\n",
      "                (ssnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
      "        (f1): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), groups=8, bias=False)\n",
      "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): Dropout2d(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): BCResBlock(\n",
      "        (f2): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(2, 1), groups=16, bias=False)\n",
      "              (1): SubSpectralNorm(\n",
      "                (ssnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
      "        (f1): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), groups=16, bias=False)\n",
      "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): Dropout2d(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): BCResBlock(\n",
      "        (f2): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(24, 24, kernel_size=(3, 1), stride=(2, 1), groups=24, bias=False)\n",
      "              (1): SubSpectralNorm(\n",
      "                (ssnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
      "        (f1): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), groups=24, bias=False)\n",
      "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): Dropout2d(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df8963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCResNets(\n",
       "  (cnn_head): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (BCBlocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(3, 1), stride=(2, 1), groups=8, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), groups=8, bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(2, 1), groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 1), stride=(2, 1), groups=24, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), groups=24, bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ff9708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1, iters: 100%|██████████| 317/317 [01:35<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 2.0780 - Accuracy: 28.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2, iters: 100%|██████████| 317/317 [00:34<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Loss: 0.9654 - Accuracy: 69.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3, iters: 100%|██████████| 317/317 [00:19<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Loss: 0.6070 - Accuracy: 80.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4, iters: 100%|██████████| 317/317 [00:17<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Loss: 0.5165 - Accuracy: 83.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5, iters: 100%|██████████| 317/317 [00:18<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Loss: 0.4869 - Accuracy: 84.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6, iters: 100%|██████████| 317/317 [00:17<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Loss: 0.4576 - Accuracy: 85.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7, iters: 100%|██████████| 317/317 [00:18<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Loss: 0.4515 - Accuracy: 85.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8, iters: 100%|██████████| 317/317 [00:17<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Loss: 0.4551 - Accuracy: 85.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9, iters: 100%|██████████| 317/317 [00:18<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Loss: 0.4502 - Accuracy: 85.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10, iters: 100%|██████████| 317/317 [00:17<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Loss: 0.4207 - Accuracy: 86.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11, iters: 100%|██████████| 317/317 [00:18<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Loss: 0.4460 - Accuracy: 85.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12, iters: 100%|██████████| 317/317 [00:18<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Loss: 0.4271 - Accuracy: 86.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13, iters: 100%|██████████| 317/317 [00:18<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Loss: 0.4257 - Accuracy: 86.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14, iters: 100%|██████████| 317/317 [00:18<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Loss: 0.4385 - Accuracy: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15, iters: 100%|██████████| 317/317 [00:17<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Loss: 0.4163 - Accuracy: 86.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16, iters: 100%|██████████| 317/317 [00:18<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Loss: 0.4230 - Accuracy: 86.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17, iters: 100%|██████████| 317/317 [00:17<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Loss: 0.4150 - Accuracy: 86.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18, iters: 100%|██████████| 317/317 [00:18<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Loss: 0.4092 - Accuracy: 87.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19, iters: 100%|██████████| 317/317 [00:18<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Loss: 0.3883 - Accuracy: 87.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20, iters: 100%|██████████| 317/317 [00:17<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Loss: 0.4098 - Accuracy: 87.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21, iters: 100%|██████████| 317/317 [00:18<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Loss: 0.4088 - Accuracy: 86.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 22, iters: 100%|██████████| 317/317 [00:18<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Loss: 0.3866 - Accuracy: 87.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 23, iters: 100%|██████████| 317/317 [00:18<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Loss: 0.4109 - Accuracy: 87.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 24, iters: 100%|██████████| 317/317 [00:17<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Loss: 0.3962 - Accuracy: 87.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 25, iters: 100%|██████████| 317/317 [00:18<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Loss: 0.4167 - Accuracy: 86.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 26, iters: 100%|██████████| 317/317 [00:18<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Loss: 0.3990 - Accuracy: 87.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 27, iters: 100%|██████████| 317/317 [00:17<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Loss: 0.4416 - Accuracy: 86.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 28, iters: 100%|██████████| 317/317 [00:18<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Loss: 0.4114 - Accuracy: 86.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 29, iters: 100%|██████████| 317/317 [00:18<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Loss: 0.3932 - Accuracy: 87.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 30, iters: 100%|██████████| 317/317 [00:17<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 - Loss: 0.4098 - Accuracy: 86.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 31, iters: 100%|██████████| 317/317 [00:18<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 - Loss: 0.3928 - Accuracy: 87.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 32, iters: 100%|██████████| 317/317 [00:18<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 - Loss: 0.4008 - Accuracy: 87.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 33, iters: 100%|██████████| 317/317 [00:18<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 - Loss: 0.3996 - Accuracy: 87.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 34, iters: 100%|██████████| 317/317 [00:18<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 - Loss: 0.3830 - Accuracy: 87.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 35, iters: 100%|██████████| 317/317 [00:19<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 - Loss: 0.4019 - Accuracy: 87.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 36, iters: 100%|██████████| 317/317 [00:18<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 - Loss: 0.3887 - Accuracy: 87.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 37, iters: 100%|██████████| 317/317 [00:18<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 - Loss: 0.4074 - Accuracy: 87.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 38, iters: 100%|██████████| 317/317 [00:18<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 - Loss: 0.4220 - Accuracy: 86.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 39, iters: 100%|██████████| 317/317 [00:19<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 - Loss: 0.3958 - Accuracy: 87.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 40, iters: 100%|██████████| 317/317 [00:19<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 - Loss: 0.3880 - Accuracy: 87.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 41, iters: 100%|██████████| 317/317 [00:18<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 - Loss: 0.3893 - Accuracy: 87.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 42, iters: 100%|██████████| 317/317 [00:18<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 - Loss: 0.3751 - Accuracy: 88.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 43, iters: 100%|██████████| 317/317 [00:18<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 - Loss: 0.3654 - Accuracy: 88.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 44, iters: 100%|██████████| 317/317 [00:18<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 - Loss: 0.3788 - Accuracy: 87.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 45, iters: 100%|██████████| 317/317 [00:18<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 - Loss: 0.3681 - Accuracy: 88.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 46, iters: 100%|██████████| 317/317 [00:18<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 - Loss: 0.3934 - Accuracy: 87.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 47, iters: 100%|██████████| 317/317 [00:18<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 - Loss: 0.3698 - Accuracy: 88.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 48, iters: 100%|██████████| 317/317 [00:18<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 - Loss: 0.3570 - Accuracy: 88.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 49, iters: 100%|██████████| 317/317 [00:18<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 - Loss: 0.3559 - Accuracy: 88.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 50, iters: 100%|██████████| 317/317 [00:18<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 - Loss: 0.3604 - Accuracy: 88.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 51, iters: 100%|██████████| 317/317 [00:18<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 - Loss: 0.3792 - Accuracy: 88.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 52, iters: 100%|██████████| 317/317 [00:18<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 - Loss: 0.3578 - Accuracy: 88.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 53, iters: 100%|██████████| 317/317 [00:18<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 - Loss: 0.3616 - Accuracy: 88.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 54, iters: 100%|██████████| 317/317 [00:18<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 - Loss: 0.3504 - Accuracy: 88.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 55, iters: 100%|██████████| 317/317 [00:18<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 - Loss: 0.3484 - Accuracy: 89.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 56, iters: 100%|██████████| 317/317 [00:18<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 - Loss: 0.3379 - Accuracy: 89.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 57, iters: 100%|██████████| 317/317 [00:18<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 - Loss: 0.3423 - Accuracy: 89.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 58, iters: 100%|██████████| 317/317 [00:18<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 - Loss: 0.3477 - Accuracy: 89.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 59, iters: 100%|██████████| 317/317 [00:18<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 - Loss: 0.3458 - Accuracy: 89.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 60, iters: 100%|██████████| 317/317 [00:18<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 - Loss: 0.3358 - Accuracy: 89.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 61, iters: 100%|██████████| 317/317 [00:18<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 - Loss: 0.3449 - Accuracy: 89.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 62, iters: 100%|██████████| 317/317 [00:18<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 - Loss: 0.3447 - Accuracy: 89.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 63, iters: 100%|██████████| 317/317 [00:18<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 - Loss: 0.3300 - Accuracy: 89.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 64, iters: 100%|██████████| 317/317 [00:18<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 - Loss: 0.3302 - Accuracy: 89.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 65, iters: 100%|██████████| 317/317 [00:18<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 - Loss: 0.3274 - Accuracy: 89.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 66, iters: 100%|██████████| 317/317 [00:18<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 - Loss: 0.3187 - Accuracy: 90.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 67, iters: 100%|██████████| 317/317 [00:18<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 - Loss: 0.3147 - Accuracy: 90.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 68, iters: 100%|██████████| 317/317 [00:18<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 - Loss: 0.3080 - Accuracy: 90.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 69, iters: 100%|██████████| 317/317 [00:19<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 - Loss: 0.3020 - Accuracy: 90.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 70, iters: 100%|██████████| 317/317 [00:18<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 - Loss: 0.3082 - Accuracy: 90.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 71, iters: 100%|██████████| 317/317 [00:18<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 - Loss: 0.3031 - Accuracy: 90.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 72, iters: 100%|██████████| 317/317 [00:18<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 - Loss: 0.2923 - Accuracy: 90.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 73, iters: 100%|██████████| 317/317 [00:18<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 - Loss: 0.2958 - Accuracy: 90.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 74, iters: 100%|██████████| 317/317 [00:18<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 - Loss: 0.2976 - Accuracy: 90.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 75, iters: 100%|██████████| 317/317 [00:18<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 - Loss: 0.2946 - Accuracy: 90.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 76, iters: 100%|██████████| 317/317 [00:18<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 - Loss: 0.2882 - Accuracy: 91.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 77, iters: 100%|██████████| 317/317 [00:18<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 - Loss: 0.2851 - Accuracy: 91.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 78, iters: 100%|██████████| 317/317 [00:18<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 - Loss: 0.2823 - Accuracy: 91.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 79, iters: 100%|██████████| 317/317 [00:18<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 - Loss: 0.2785 - Accuracy: 91.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 80, iters: 100%|██████████| 317/317 [00:18<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 - Loss: 0.2701 - Accuracy: 91.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 81, iters: 100%|██████████| 317/317 [00:18<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 - Loss: 0.2709 - Accuracy: 91.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 82, iters: 100%|██████████| 317/317 [00:18<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 - Loss: 0.2688 - Accuracy: 91.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 83, iters: 100%|██████████| 317/317 [00:18<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 - Loss: 0.2679 - Accuracy: 91.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 84, iters: 100%|██████████| 317/317 [00:18<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 - Loss: 0.2613 - Accuracy: 91.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 85, iters: 100%|██████████| 317/317 [00:18<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 - Loss: 0.2576 - Accuracy: 92.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 86, iters: 100%|██████████| 317/317 [00:18<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 - Loss: 0.2552 - Accuracy: 92.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 87, iters: 100%|██████████| 317/317 [00:18<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 - Loss: 0.2506 - Accuracy: 92.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 88, iters: 100%|██████████| 317/317 [00:18<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 - Loss: 0.2497 - Accuracy: 92.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 89, iters: 100%|██████████| 317/317 [00:18<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 - Loss: 0.2473 - Accuracy: 92.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 90, iters: 100%|██████████| 317/317 [00:18<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 - Loss: 0.2429 - Accuracy: 92.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 91, iters: 100%|██████████| 317/317 [00:19<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 - Loss: 0.2425 - Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 92, iters: 100%|██████████| 317/317 [00:18<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 - Loss: 0.2375 - Accuracy: 92.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 93, iters: 100%|██████████| 317/317 [00:18<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 - Loss: 0.2371 - Accuracy: 92.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 94, iters: 100%|██████████| 317/317 [00:18<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 - Loss: 0.2356 - Accuracy: 92.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 95, iters: 100%|██████████| 317/317 [00:18<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 - Loss: 0.2334 - Accuracy: 92.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 96, iters: 100%|██████████| 317/317 [00:18<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 - Loss: 0.2319 - Accuracy: 92.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 97, iters: 100%|██████████| 317/317 [00:18<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 - Loss: 0.2324 - Accuracy: 92.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 98, iters: 100%|██████████| 317/317 [00:18<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 - Loss: 0.2280 - Accuracy: 93.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 99, iters: 100%|██████████| 317/317 [00:18<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 - Loss: 0.2297 - Accuracy: 93.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 100, iters: 100%|██████████| 317/317 [00:18<00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 - Loss: 0.2273 - Accuracy: 93.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_epoch = 100\n",
    "warmup_epoch = 5\n",
    "init_lr = 1e-1\n",
    "lr_lower_limit = 0\n",
    "int_bit = 4\n",
    "frac_bit = 3\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0, weight_decay=1e-3, momentum=0.9)\n",
    "n_step_warmup = len(train_loader) * warmup_epoch\n",
    "total_iter = len(train_loader) * total_epoch\n",
    "iterations = 0\n",
    "\n",
    "losses=[]\n",
    "# train\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for sample in tqdm(train_loader, desc=\"epoch %d, iters\" % (epoch + 1)):\n",
    "        # lr cos schedule\n",
    "        iterations += 1\n",
    "        if iterations < n_step_warmup:\n",
    "            lr = init_lr * iterations / n_step_warmup\n",
    "        else:\n",
    "            lr = lr_lower_limit + 0.5 * (init_lr - lr_lower_limit) * (\n",
    "                1\n",
    "                + np.cos(\n",
    "                    np.pi * (iterations - n_step_warmup) / (total_iter - n_step_warmup)\n",
    "                )\n",
    "            )\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        inputs, labels = sample\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs = sp_transform(inputs)\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate and print epoch loss and accuracy\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{total_epoch} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93d48d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 94.924\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "\n",
    "\n",
    "def Test(dataset, loader, augment):\n",
    "        \"\"\"\n",
    "        Tests the model on a given dataset.\n",
    "\n",
    "        Parameters:\n",
    "            dataset (Dataset): The dataset to test the model on.\n",
    "            loader (DataLoader): The data loader to use for batching the data.\n",
    "            augment (bool): Flag indicating whether to use data augmentation during testing.\n",
    "\n",
    "        Returns:\n",
    "            float: The accuracy of the model on the given dataset.\n",
    "        \"\"\"\n",
    "        #model.eval()\n",
    "        true_count = 0.0\n",
    "        num_testdata = float(len(dataset))\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                inputs = sp_transform(inputs)\n",
    "                outputs = model(inputs)\n",
    "                prediction = torch.argmax(outputs, dim=-1)\n",
    "                true_count += prediction.eq(labels).sum().item()\n",
    "            acc = true_count / num_testdata * 100.0  # percentage\n",
    "            return acc\n",
    "\n",
    "\n",
    "test_acc = Test(test_set, test_loader, augment=False)  # official testset\n",
    "print(\"test acc: %.3f\" % (test_acc))\n",
    "print(\"End.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a63b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tensor):\n",
    "    # Use the model to predict the label of the waveform\n",
    "    tensor = tensor.to(device)\n",
    "    tensor = sp_transform(tensor)\n",
    "    tensor=tensor.unsqueeze(0)\n",
    "    tensor = model(tensor)\n",
    "    tensor =  torch.argmax(tensor, dim=-1)\n",
    "    #tensor = tensor.squeeze()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c33288bd-5b94-4a8b-ba1c-e5beaed53662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T08:43:02.552338Z",
     "iopub.status.busy": "2024-08-27T08:43:02.552338Z",
     "iopub.status.idle": "2024-08-27T08:43:02.929210Z",
     "shell.execute_reply": "2024-08-27T08:43:02.929210Z",
     "shell.execute_reply.started": "2024-08-27T08:43:02.552338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses);\n",
    "plt.title(\"training loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab8ee69-302d-4a8f-859c-d47affb493d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T08:55:29.680962Z",
     "iopub.status.busy": "2024-08-27T08:55:29.679965Z",
     "iopub.status.idle": "2024-08-27T08:56:52.870719Z",
     "shell.execute_reply": "2024-08-27T08:56:52.867626Z",
     "shell.execute_reply.started": "2024-08-27T08:55:29.680962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label '0': 90.96%\n",
      "Accuracy for label '1': 97.61%\n",
      "Accuracy for label '2': 93.33%\n",
      "Accuracy for label '3': 92.24%\n",
      "Accuracy for label '4': 88.67%\n",
      "Accuracy for label '5': 96.84%\n",
      "Accuracy for label '6': 95.20%\n",
      "Accuracy for label '7': 91.41%\n",
      "Accuracy for label '8': 90.30%\n",
      "Accuracy for label '9': 96.84%\n",
      "Accuracy for label '10': 91.54%\n",
      "Accuracy for label '11': 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 실제 라벨과 예측된 라벨을 저장할 리스트 초기화\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# 테스트 셋을 순회하며 예측 수행\n",
    "for i, (waveform, sample_rate, utterance, *_) in enumerate(test_set):\n",
    "    output = predict(waveform)\n",
    "    output=output.cpu()[0]\n",
    "    true_labels.append(utterance)\n",
    "    predicted_labels.append(output)\n",
    "\n",
    "# 라벨 리스트 정의 (unknown 라벨도 포함)\n",
    "labels_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=labels_list)\n",
    "\n",
    "# 각 라벨에 대한 정확도 계산\n",
    "label_accuracies = {}\n",
    "for i, label in enumerate(labels_list):\n",
    "    true_positive = cm[i, i]\n",
    "    total_samples = cm[i, :].sum()\n",
    "    accuracy = true_positive / total_samples if total_samples > 0 else 0\n",
    "    label_accuracies[label] = accuracy\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_list, yticklabels=labels_list)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# # 혼동 행렬을 텍스트 파일로 저장\n",
    "# output_matrix_path = '/content/confusion_matrix.txt'\n",
    "# np.savetxt(output_matrix_path, cm, fmt='%d', delimiter=',', header=','.join(labels_list), comments='')\n",
    "# print(f\"Confusion matrix saved to {output_matrix_path}\")\n",
    "\n",
    "# 각 라벨에 대한 정확도 출력\n",
    "for label, accuracy in label_accuracies.items():\n",
    "    print(f\"Accuracy for label '{label}': {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe3756",
   "metadata": {},
   "source": [
    "0: unknown, 1: yes, 2: no, 3: up, 4: down, 5:left, 6:right, 7:on, 8:off, 9:stop, 10:go, 11:background_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd747fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCResNets(\n",
       "  (cnn_head): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (BCBlocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(3, 1), stride=(2, 1), groups=8, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), groups=8, bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(2, 1), groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 1), stride=(2, 1), groups=24, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, 29))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), groups=24, bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96a714b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 끝난 신경망 모델\n",
    "params = model.state_dict()\n",
    "# model.prm라는 파일로 저장\n",
    "torch.save(params, \"model_1.prm\", pickle_protocol = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a579767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0497e-01,  1.0112e-01, -1.0195e-06, -1.1315e-03,  1.8005e-01,\n",
      "         3.4204e-01,  7.7336e-04, -6.5521e-05, -1.6877e-05, -8.7035e-02,\n",
      "         1.1520e-01, -1.6303e-05,  3.5798e-01,  2.7191e-01, -1.6587e-01,\n",
      "        -5.2825e-01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(params['cnn_head.1.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04ea4e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "cnn_head.0.weight \t torch.Size([16, 1, 3, 3])\n",
      "cnn_head.1.weight \t torch.Size([16])\n",
      "cnn_head.1.bias \t torch.Size([16])\n",
      "cnn_head.1.running_mean \t torch.Size([16])\n",
      "cnn_head.1.running_var \t torch.Size([16])\n",
      "cnn_head.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.0.0.f2.0.block.0.weight \t torch.Size([8, 16, 1, 1])\n",
      "BCBlocks.0.0.f2.0.block.1.weight \t torch.Size([8])\n",
      "BCBlocks.0.0.f2.0.block.1.bias \t torch.Size([8])\n",
      "BCBlocks.0.0.f2.0.block.1.running_mean \t torch.Size([8])\n",
      "BCBlocks.0.0.f2.0.block.1.running_var \t torch.Size([8])\n",
      "BCBlocks.0.0.f2.0.block.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.0.0.f2.1.block.0.weight \t torch.Size([8, 1, 3, 1])\n",
      "BCBlocks.0.0.f2.1.block.1.ssnorm.weight \t torch.Size([32])\n",
      "BCBlocks.0.0.f2.1.block.1.ssnorm.bias \t torch.Size([32])\n",
      "BCBlocks.0.0.f2.1.block.1.ssnorm.running_mean \t torch.Size([32])\n",
      "BCBlocks.0.0.f2.1.block.1.ssnorm.running_var \t torch.Size([32])\n",
      "BCBlocks.0.0.f2.1.block.1.ssnorm.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.0.0.f1.0.block.0.weight \t torch.Size([8, 1, 1, 3])\n",
      "BCBlocks.0.0.f1.0.block.1.weight \t torch.Size([8])\n",
      "BCBlocks.0.0.f1.0.block.1.bias \t torch.Size([8])\n",
      "BCBlocks.0.0.f1.0.block.1.running_mean \t torch.Size([8])\n",
      "BCBlocks.0.0.f1.0.block.1.running_var \t torch.Size([8])\n",
      "BCBlocks.0.0.f1.0.block.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.0.0.f1.1.weight \t torch.Size([8, 8, 1, 1])\n",
      "BCBlocks.1.0.f2.0.block.0.weight \t torch.Size([16, 8, 1, 1])\n",
      "BCBlocks.1.0.f2.0.block.1.weight \t torch.Size([16])\n",
      "BCBlocks.1.0.f2.0.block.1.bias \t torch.Size([16])\n",
      "BCBlocks.1.0.f2.0.block.1.running_mean \t torch.Size([16])\n",
      "BCBlocks.1.0.f2.0.block.1.running_var \t torch.Size([16])\n",
      "BCBlocks.1.0.f2.0.block.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.1.0.f2.1.block.0.weight \t torch.Size([16, 1, 3, 1])\n",
      "BCBlocks.1.0.f2.1.block.1.ssnorm.weight \t torch.Size([48])\n",
      "BCBlocks.1.0.f2.1.block.1.ssnorm.bias \t torch.Size([48])\n",
      "BCBlocks.1.0.f2.1.block.1.ssnorm.running_mean \t torch.Size([48])\n",
      "BCBlocks.1.0.f2.1.block.1.ssnorm.running_var \t torch.Size([48])\n",
      "BCBlocks.1.0.f2.1.block.1.ssnorm.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.1.0.f1.0.block.0.weight \t torch.Size([16, 1, 1, 3])\n",
      "BCBlocks.1.0.f1.0.block.1.weight \t torch.Size([16])\n",
      "BCBlocks.1.0.f1.0.block.1.bias \t torch.Size([16])\n",
      "BCBlocks.1.0.f1.0.block.1.running_mean \t torch.Size([16])\n",
      "BCBlocks.1.0.f1.0.block.1.running_var \t torch.Size([16])\n",
      "BCBlocks.1.0.f1.0.block.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.1.0.f1.1.weight \t torch.Size([16, 16, 1, 1])\n",
      "BCBlocks.2.0.f2.0.block.0.weight \t torch.Size([24, 16, 1, 1])\n",
      "BCBlocks.2.0.f2.0.block.1.weight \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.0.block.1.bias \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.0.block.1.running_mean \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.0.block.1.running_var \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.0.block.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.2.0.f2.1.block.0.weight \t torch.Size([24, 1, 3, 1])\n",
      "BCBlocks.2.0.f2.1.block.1.ssnorm.weight \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.1.block.1.ssnorm.bias \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.1.block.1.ssnorm.running_mean \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.1.block.1.ssnorm.running_var \t torch.Size([24])\n",
      "BCBlocks.2.0.f2.1.block.1.ssnorm.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.2.0.f1.0.block.0.weight \t torch.Size([24, 1, 1, 3])\n",
      "BCBlocks.2.0.f1.0.block.1.weight \t torch.Size([24])\n",
      "BCBlocks.2.0.f1.0.block.1.bias \t torch.Size([24])\n",
      "BCBlocks.2.0.f1.0.block.1.running_mean \t torch.Size([24])\n",
      "BCBlocks.2.0.f1.0.block.1.running_var \t torch.Size([24])\n",
      "BCBlocks.2.0.f1.0.block.1.num_batches_tracked \t torch.Size([])\n",
      "BCBlocks.2.0.f1.1.weight \t torch.Size([24, 24, 1, 1])\n",
      "classifier.0.weight \t torch.Size([24])\n",
      "classifier.0.bias \t torch.Size([24])\n",
      "classifier.0.running_mean \t torch.Size([24])\n",
      "classifier.0.running_var \t torch.Size([24])\n",
      "classifier.0.num_batches_tracked \t torch.Size([])\n",
      "classifier.1.weight \t torch.Size([12, 24, 1, 1])\n",
      "classifier.1.bias \t torch.Size([12])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'momentum_buffer': tensor([[[[-6.1707e-04, -2.2269e-01, -2.3010e-01],\n",
      "          [ 5.3217e-02, -8.4370e-02, -1.1430e-01],\n",
      "          [ 8.0820e-02, -6.1459e-03, -8.2034e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1698e+00,  9.8335e-01,  1.0575e+00],\n",
      "          [ 1.2480e+00,  1.0059e+00,  1.0258e+00],\n",
      "          [ 1.1210e+00,  8.8005e-01,  9.3982e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4096e-08, -1.5839e-08,  9.4962e-09],\n",
      "          [-1.5020e-08,  3.1833e-09, -1.2385e-08],\n",
      "          [-3.4171e-09,  2.6560e-08, -1.1454e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.0546e-06, -1.2672e-05, -1.4647e-05],\n",
      "          [ 2.3668e-06, -7.0734e-06, -8.3027e-06],\n",
      "          [-2.5423e-06,  8.8461e-07, -1.4358e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7144e-01,  1.4196e-01,  7.0640e-02],\n",
      "          [ 1.5286e-01,  1.0858e-01,  2.2362e-02],\n",
      "          [ 1.5135e-01,  1.3236e-01,  8.4523e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3983e-01, -3.8897e-01, -4.8360e-01],\n",
      "          [-3.6709e-01, -4.3254e-01, -5.5785e-01],\n",
      "          [-3.9966e-01, -4.3117e-01, -4.7802e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5731e-05,  1.6354e-05,  7.8735e-06],\n",
      "          [ 6.3860e-06,  5.9667e-06, -3.5415e-06],\n",
      "          [ 2.2537e-06,  2.3016e-05,  3.1147e-06]]],\n",
      "\n",
      "\n",
      "        [[[-8.2402e-07, -1.1873e-06, -6.2413e-07],\n",
      "          [-3.8281e-07, -5.0798e-07, -1.6475e-08],\n",
      "          [-5.0671e-08,  1.3998e-07,  4.6454e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.0853e-07, -4.0687e-07, -3.4613e-07],\n",
      "          [-1.1009e-08, -5.9182e-08, -1.8869e-07],\n",
      "          [ 7.4676e-08,  1.6635e-07,  2.2091e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.1888e-02, -7.7317e-03,  5.2919e-02],\n",
      "          [-5.5318e-02, -3.2479e-02,  1.3571e-02],\n",
      "          [-8.9301e-02, -3.4896e-02,  1.1487e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5160e-01,  5.0390e-01,  3.6222e-01],\n",
      "          [ 7.3400e-01,  6.5290e-01,  4.0505e-01],\n",
      "          [ 1.0429e+00,  1.0595e+00,  6.3702e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5601e-07,  9.0883e-08, -1.0087e-07],\n",
      "          [ 9.0362e-08,  8.5418e-08, -2.9025e-08],\n",
      "          [ 7.0556e-08,  6.5206e-08, -2.9281e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9308e-01,  4.4160e-01,  4.2106e-01],\n",
      "          [ 6.4741e-01,  6.2181e-01,  5.6906e-01],\n",
      "          [ 7.8078e-01,  7.2617e-01,  5.9342e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0552e-01,  2.5358e-01,  2.4412e-01],\n",
      "          [ 2.2553e-01,  1.7865e-01,  2.0457e-01],\n",
      "          [ 1.7291e-01,  1.0260e-01,  6.6913e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4964e+00, -1.0940e+00, -1.1591e+00],\n",
      "          [-1.5683e+00, -1.3634e+00, -1.5594e+00],\n",
      "          [-1.8596e+00, -1.9229e+00, -2.1222e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6539e-01,  1.5810e-01,  1.3758e-02],\n",
      "          [ 1.9000e-01,  1.6247e-01,  3.0694e-03],\n",
      "          [ 1.7103e-01,  1.3231e-01, -1.2403e-02]]]], device='cuda:0')}, 1: {'momentum_buffer': tensor([-2.6323e-01, -6.8190e-02,  3.6096e-09,  1.3145e-04,  1.8127e-01,\n",
      "        -3.4219e-01,  2.5752e-04,  2.1805e-07,  5.2649e-08, -1.1359e-01,\n",
      "         1.2191e+00,  3.6888e-08,  8.1238e-01,  3.5670e-01, -1.3389e+00,\n",
      "         2.5164e-01], device='cuda:0')}, 2: {'momentum_buffer': tensor([-3.0956e-01,  2.7816e-01, -1.0195e-08,  8.7148e-05,  2.1928e-01,\n",
      "        -3.2411e-01,  7.7335e-06, -6.5521e-07, -1.6877e-07, -6.4261e-02,\n",
      "         1.0686e-01, -1.6303e-07, -5.2485e-01,  2.5758e-01, -2.7103e-01,\n",
      "         2.0718e-01], device='cuda:0')}, 3: {'momentum_buffer': tensor([[[[ 1.3507e-01]],\n",
      "\n",
      "         [[-9.5639e-02]],\n",
      "\n",
      "         [[-4.1134e-10]],\n",
      "\n",
      "         [[ 2.2532e-05]],\n",
      "\n",
      "         [[-2.5461e-01]],\n",
      "\n",
      "         [[-2.0191e-02]],\n",
      "\n",
      "         [[ 1.6519e-04]],\n",
      "\n",
      "         [[ 6.4595e-07]],\n",
      "\n",
      "         [[ 3.3022e-07]],\n",
      "\n",
      "         [[ 1.4475e-01]],\n",
      "\n",
      "         [[ 2.9046e-01]],\n",
      "\n",
      "         [[ 3.1435e-08]],\n",
      "\n",
      "         [[ 2.1179e-01]],\n",
      "\n",
      "         [[ 4.0018e-01]],\n",
      "\n",
      "         [[-3.0299e-02]],\n",
      "\n",
      "         [[-1.7546e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9466e-02]],\n",
      "\n",
      "         [[-2.3518e-01]],\n",
      "\n",
      "         [[-5.7538e-10]],\n",
      "\n",
      "         [[-2.5457e-05]],\n",
      "\n",
      "         [[ 7.9932e-02]],\n",
      "\n",
      "         [[-4.2633e-01]],\n",
      "\n",
      "         [[-2.3350e-04]],\n",
      "\n",
      "         [[-6.3180e-07]],\n",
      "\n",
      "         [[-4.3618e-08]],\n",
      "\n",
      "         [[ 2.0815e-01]],\n",
      "\n",
      "         [[-4.6336e-01]],\n",
      "\n",
      "         [[ 6.9524e-08]],\n",
      "\n",
      "         [[ 2.0128e-02]],\n",
      "\n",
      "         [[-4.3461e-01]],\n",
      "\n",
      "         [[-2.2186e-01]],\n",
      "\n",
      "         [[-4.7830e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.0507e-03]],\n",
      "\n",
      "         [[-1.9325e-03]],\n",
      "\n",
      "         [[ 1.5174e-08]],\n",
      "\n",
      "         [[-1.4272e-07]],\n",
      "\n",
      "         [[-2.0191e-01]],\n",
      "\n",
      "         [[ 3.9025e-01]],\n",
      "\n",
      "         [[ 2.0915e-04]],\n",
      "\n",
      "         [[ 5.0507e-07]],\n",
      "\n",
      "         [[ 1.8686e-07]],\n",
      "\n",
      "         [[ 9.2056e-02]],\n",
      "\n",
      "         [[ 3.8818e-01]],\n",
      "\n",
      "         [[-5.2331e-09]],\n",
      "\n",
      "         [[ 1.5915e-01]],\n",
      "\n",
      "         [[ 3.3278e-01]],\n",
      "\n",
      "         [[ 1.7495e-01]],\n",
      "\n",
      "         [[-1.8390e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0213e-02]],\n",
      "\n",
      "         [[-6.7032e-02]],\n",
      "\n",
      "         [[ 1.2957e-08]],\n",
      "\n",
      "         [[ 2.0708e-05]],\n",
      "\n",
      "         [[ 1.6188e-01]],\n",
      "\n",
      "         [[ 1.5784e-01]],\n",
      "\n",
      "         [[-1.4371e-04]],\n",
      "\n",
      "         [[ 3.5833e-07]],\n",
      "\n",
      "         [[ 4.5089e-07]],\n",
      "\n",
      "         [[ 9.1227e-02]],\n",
      "\n",
      "         [[-1.4983e-01]],\n",
      "\n",
      "         [[-3.7373e-09]],\n",
      "\n",
      "         [[-1.4229e-01]],\n",
      "\n",
      "         [[-4.0292e-01]],\n",
      "\n",
      "         [[-8.5792e-02]],\n",
      "\n",
      "         [[ 9.3865e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1707e-01]],\n",
      "\n",
      "         [[-6.5678e-01]],\n",
      "\n",
      "         [[ 1.0109e-09]],\n",
      "\n",
      "         [[ 2.6870e-06]],\n",
      "\n",
      "         [[ 1.5110e-01]],\n",
      "\n",
      "         [[-8.3538e-01]],\n",
      "\n",
      "         [[-7.2600e-04]],\n",
      "\n",
      "         [[-1.6728e-07]],\n",
      "\n",
      "         [[-1.1359e-08]],\n",
      "\n",
      "         [[-1.9941e-01]],\n",
      "\n",
      "         [[-9.7563e-01]],\n",
      "\n",
      "         [[-7.8430e-08]],\n",
      "\n",
      "         [[-4.0283e-01]],\n",
      "\n",
      "         [[-1.3394e+00]],\n",
      "\n",
      "         [[-8.4918e-01]],\n",
      "\n",
      "         [[-1.0450e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8760e-01]],\n",
      "\n",
      "         [[-1.6172e-02]],\n",
      "\n",
      "         [[ 5.2523e-10]],\n",
      "\n",
      "         [[ 1.8450e-05]],\n",
      "\n",
      "         [[ 1.2692e-01]],\n",
      "\n",
      "         [[-2.6042e-01]],\n",
      "\n",
      "         [[-1.8367e-04]],\n",
      "\n",
      "         [[-5.7654e-07]],\n",
      "\n",
      "         [[ 1.4073e-07]],\n",
      "\n",
      "         [[-2.0418e-01]],\n",
      "\n",
      "         [[-1.9368e-02]],\n",
      "\n",
      "         [[ 7.9221e-09]],\n",
      "\n",
      "         [[-1.5242e-01]],\n",
      "\n",
      "         [[-8.7126e-02]],\n",
      "\n",
      "         [[-6.5789e-02]],\n",
      "\n",
      "         [[ 1.6090e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8049e-01]],\n",
      "\n",
      "         [[ 4.1668e-01]],\n",
      "\n",
      "         [[-8.5952e-09]],\n",
      "\n",
      "         [[ 1.2795e-05]],\n",
      "\n",
      "         [[ 4.7313e-02]],\n",
      "\n",
      "         [[ 3.8705e-01]],\n",
      "\n",
      "         [[ 3.8642e-04]],\n",
      "\n",
      "         [[-2.6727e-07]],\n",
      "\n",
      "         [[ 6.9311e-08]],\n",
      "\n",
      "         [[ 1.4819e-01]],\n",
      "\n",
      "         [[ 6.0790e-01]],\n",
      "\n",
      "         [[ 4.9740e-08]],\n",
      "\n",
      "         [[-4.0021e-02]],\n",
      "\n",
      "         [[ 6.0493e-01]],\n",
      "\n",
      "         [[ 3.1267e-01]],\n",
      "\n",
      "         [[ 2.5485e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6168e-02]],\n",
      "\n",
      "         [[-3.7218e-01]],\n",
      "\n",
      "         [[ 4.8707e-09]],\n",
      "\n",
      "         [[ 3.8910e-06]],\n",
      "\n",
      "         [[-1.9846e-01]],\n",
      "\n",
      "         [[ 1.3101e-01]],\n",
      "\n",
      "         [[-8.2426e-05]],\n",
      "\n",
      "         [[ 8.2052e-07]],\n",
      "\n",
      "         [[ 9.9258e-08]],\n",
      "\n",
      "         [[ 1.1526e-01]],\n",
      "\n",
      "         [[ 2.2825e-02]],\n",
      "\n",
      "         [[ 1.1229e-08]],\n",
      "\n",
      "         [[-2.8039e-01]],\n",
      "\n",
      "         [[-2.3018e-01]],\n",
      "\n",
      "         [[ 5.2124e-02]],\n",
      "\n",
      "         [[-5.2304e-02]]]], device='cuda:0')}, 4: {'momentum_buffer': tensor([ 0.2025, -0.0468,  0.0489,  0.4668, -0.2391, -0.1321, -0.0537,  0.1440],\n",
      "       device='cuda:0')}, 5: {'momentum_buffer': tensor([-0.2774,  0.0038, -0.0858,  0.5914, -0.3348,  0.1771, -0.0892,  0.0019],\n",
      "       device='cuda:0')}, 6: {'momentum_buffer': tensor([[[[ 0.0979],\n",
      "          [-0.0467],\n",
      "          [-0.3396]]],\n",
      "\n",
      "\n",
      "        [[[-0.1533],\n",
      "          [-0.1003],\n",
      "          [ 0.0026]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0884],\n",
      "          [-0.0361],\n",
      "          [-0.0398]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0569],\n",
      "          [-0.0296],\n",
      "          [-0.1087]]],\n",
      "\n",
      "\n",
      "        [[[-0.1497],\n",
      "          [ 0.1096],\n",
      "          [ 0.0395]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7190],\n",
      "          [ 0.5562],\n",
      "          [ 0.5035]]],\n",
      "\n",
      "\n",
      "        [[[-0.1546],\n",
      "          [-0.0546],\n",
      "          [ 0.1937]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0141],\n",
      "          [-0.1646],\n",
      "          [-0.1058]]]], device='cuda:0')}, 7: {'momentum_buffer': tensor([-0.1215,  1.2413,  0.1607, -0.4141, -0.0302,  0.3584, -0.3373, -0.2769,\n",
      "         0.1095, -0.4821,  0.1728,  0.2116, -0.1017,  0.2587, -1.0815,  0.0131,\n",
      "        -0.5016, -1.0300, -0.1871,  0.0290, -0.4742,  0.7004,  0.9928,  0.1116,\n",
      "         0.2944,  0.7714,  0.0147,  0.1699, -0.9980, -1.5667, -0.7674, -0.9606],\n",
      "       device='cuda:0')}, 8: {'momentum_buffer': tensor([-0.1148,  0.6635, -0.1081, -0.2778, -0.0849, -0.0116,  0.1073, -0.1281,\n",
      "         0.0268, -0.3649,  0.4841, -0.3287,  0.2700, -0.0153, -0.0223,  0.0227,\n",
      "        -0.1179, -0.1904, -0.0318, -0.0416,  0.0218, -0.1736, -0.0643,  0.1382,\n",
      "         0.0757,  0.3188, -0.1815,  0.0721,  0.1678, -0.6139,  0.0140,  0.1306],\n",
      "       device='cuda:0')}, 9: {'momentum_buffer': tensor([[[[ 2.5131e-02,  7.9129e-02,  7.1572e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1108e-01,  8.4390e-02, -8.5843e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5483e-01,  2.0453e-01,  1.4169e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6669e-06, -8.0911e-07,  8.6596e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6244e-08,  7.5240e-08,  7.1361e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2220e-02,  4.3383e-02, -3.3279e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7347e-08,  3.0084e-07,  1.8231e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.2203e-01, -4.8623e-02, -3.6889e-02]]]], device='cuda:0')}, 10: {'momentum_buffer': tensor([ 1.4941e-01, -7.7752e-02, -1.4308e-01, -3.5153e-07,  1.6093e-08,\n",
      "        -1.4010e-01,  2.2676e-07,  1.6272e-01], device='cuda:0')}, 11: {'momentum_buffer': tensor([ 2.4208e-01, -4.7262e-02,  3.7132e-02, -1.8226e-06, -1.8043e-07,\n",
      "        -1.1205e-01, -2.5111e-06,  1.9438e-01], device='cuda:0')}, 12: {'momentum_buffer': tensor([[[[-9.9691e-02]],\n",
      "\n",
      "         [[ 1.3250e-03]],\n",
      "\n",
      "         [[ 8.2591e-02]],\n",
      "\n",
      "         [[ 8.6774e-07]],\n",
      "\n",
      "         [[-3.7794e-08]],\n",
      "\n",
      "         [[-4.7291e-02]],\n",
      "\n",
      "         [[-6.1831e-07]],\n",
      "\n",
      "         [[ 9.4479e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4073e-02]],\n",
      "\n",
      "         [[-3.3931e-02]],\n",
      "\n",
      "         [[ 3.1820e-01]],\n",
      "\n",
      "         [[-7.3577e-07]],\n",
      "\n",
      "         [[-4.2766e-08]],\n",
      "\n",
      "         [[-1.0553e-01]],\n",
      "\n",
      "         [[-1.4171e-06]],\n",
      "\n",
      "         [[ 5.7275e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6317e-02]],\n",
      "\n",
      "         [[-1.2101e-01]],\n",
      "\n",
      "         [[-6.9036e-02]],\n",
      "\n",
      "         [[ 9.7591e-07]],\n",
      "\n",
      "         [[-4.8998e-09]],\n",
      "\n",
      "         [[ 9.6241e-02]],\n",
      "\n",
      "         [[-9.8159e-07]],\n",
      "\n",
      "         [[-1.3769e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.6675e-02]],\n",
      "\n",
      "         [[-1.9031e-01]],\n",
      "\n",
      "         [[-1.0114e-01]],\n",
      "\n",
      "         [[-2.9264e-07]],\n",
      "\n",
      "         [[-1.3775e-07]],\n",
      "\n",
      "         [[-4.1147e-02]],\n",
      "\n",
      "         [[ 4.6673e-07]],\n",
      "\n",
      "         [[-4.9147e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1918e-01]],\n",
      "\n",
      "         [[ 5.0771e-02]],\n",
      "\n",
      "         [[-8.5116e-02]],\n",
      "\n",
      "         [[ 4.1110e-07]],\n",
      "\n",
      "         [[-3.8712e-08]],\n",
      "\n",
      "         [[-8.8870e-02]],\n",
      "\n",
      "         [[-7.1877e-07]],\n",
      "\n",
      "         [[-4.6975e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0012e-01]],\n",
      "\n",
      "         [[ 9.4978e-02]],\n",
      "\n",
      "         [[-4.1244e-02]],\n",
      "\n",
      "         [[-8.5466e-08]],\n",
      "\n",
      "         [[ 1.0557e-08]],\n",
      "\n",
      "         [[ 9.7693e-02]],\n",
      "\n",
      "         [[-2.5133e-07]],\n",
      "\n",
      "         [[-7.7777e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2646e-03]],\n",
      "\n",
      "         [[-4.0168e-02]],\n",
      "\n",
      "         [[ 1.1345e-01]],\n",
      "\n",
      "         [[-1.3911e-06]],\n",
      "\n",
      "         [[ 9.2003e-09]],\n",
      "\n",
      "         [[ 1.2545e-01]],\n",
      "\n",
      "         [[-1.8240e-06]],\n",
      "\n",
      "         [[-7.4626e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1275e-01]],\n",
      "\n",
      "         [[-3.6555e-02]],\n",
      "\n",
      "         [[ 6.9481e-02]],\n",
      "\n",
      "         [[ 3.3046e-07]],\n",
      "\n",
      "         [[-9.0845e-08]],\n",
      "\n",
      "         [[-2.8175e-03]],\n",
      "\n",
      "         [[-3.8688e-07]],\n",
      "\n",
      "         [[-7.9154e-02]]]], device='cuda:0')}, 13: {'momentum_buffer': tensor([[[[ 1.7393e-02]],\n",
      "\n",
      "         [[-8.6857e-02]],\n",
      "\n",
      "         [[-8.0320e-02]],\n",
      "\n",
      "         [[-6.3675e-02]],\n",
      "\n",
      "         [[ 5.2821e-02]],\n",
      "\n",
      "         [[ 3.7509e-03]],\n",
      "\n",
      "         [[-1.6824e-01]],\n",
      "\n",
      "         [[-6.1364e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8049e-02]],\n",
      "\n",
      "         [[-7.2535e-03]],\n",
      "\n",
      "         [[ 1.4152e-01]],\n",
      "\n",
      "         [[-6.2480e-02]],\n",
      "\n",
      "         [[ 7.8143e-02]],\n",
      "\n",
      "         [[-6.4381e-02]],\n",
      "\n",
      "         [[-3.2401e-01]],\n",
      "\n",
      "         [[-5.1015e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4640e-01]],\n",
      "\n",
      "         [[ 3.8734e-02]],\n",
      "\n",
      "         [[-2.1350e-01]],\n",
      "\n",
      "         [[ 1.1610e-01]],\n",
      "\n",
      "         [[ 4.1335e-02]],\n",
      "\n",
      "         [[ 3.5818e-02]],\n",
      "\n",
      "         [[-3.8738e-01]],\n",
      "\n",
      "         [[-7.7102e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6906e-01]],\n",
      "\n",
      "         [[-2.1292e-02]],\n",
      "\n",
      "         [[ 3.7786e-01]],\n",
      "\n",
      "         [[-9.9030e-02]],\n",
      "\n",
      "         [[-3.1303e-01]],\n",
      "\n",
      "         [[ 7.7907e-03]],\n",
      "\n",
      "         [[ 3.7780e-01]],\n",
      "\n",
      "         [[ 1.2626e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5568e-01]],\n",
      "\n",
      "         [[-7.1749e-04]],\n",
      "\n",
      "         [[-1.2678e-01]],\n",
      "\n",
      "         [[ 1.1522e-01]],\n",
      "\n",
      "         [[-1.1396e-03]],\n",
      "\n",
      "         [[ 6.5904e-02]],\n",
      "\n",
      "         [[ 1.8424e-01]],\n",
      "\n",
      "         [[-5.9288e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0429e-01]],\n",
      "\n",
      "         [[-1.7947e-01]],\n",
      "\n",
      "         [[-6.1863e-02]],\n",
      "\n",
      "         [[ 1.7357e-01]],\n",
      "\n",
      "         [[-2.3177e-02]],\n",
      "\n",
      "         [[ 3.2494e-01]],\n",
      "\n",
      "         [[ 8.5319e-02]],\n",
      "\n",
      "         [[ 8.5475e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7816e-02]],\n",
      "\n",
      "         [[-7.0573e-03]],\n",
      "\n",
      "         [[ 2.2217e-03]],\n",
      "\n",
      "         [[ 6.3161e-03]],\n",
      "\n",
      "         [[-7.1212e-02]],\n",
      "\n",
      "         [[ 6.6715e-02]],\n",
      "\n",
      "         [[-1.3489e-02]],\n",
      "\n",
      "         [[-1.6997e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0163e-01]],\n",
      "\n",
      "         [[ 2.4229e-01]],\n",
      "\n",
      "         [[ 7.3166e-03]],\n",
      "\n",
      "         [[ 3.8269e-02]],\n",
      "\n",
      "         [[ 9.1165e-02]],\n",
      "\n",
      "         [[ 1.3916e-02]],\n",
      "\n",
      "         [[ 1.3787e-01]],\n",
      "\n",
      "         [[ 5.0936e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1188e-01]],\n",
      "\n",
      "         [[-3.5388e-02]],\n",
      "\n",
      "         [[-6.4383e-04]],\n",
      "\n",
      "         [[-1.1865e-01]],\n",
      "\n",
      "         [[-3.2227e-01]],\n",
      "\n",
      "         [[ 1.2098e-01]],\n",
      "\n",
      "         [[ 3.7530e-01]],\n",
      "\n",
      "         [[ 3.0293e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1507e-01]],\n",
      "\n",
      "         [[ 3.3482e-02]],\n",
      "\n",
      "         [[-7.6244e-02]],\n",
      "\n",
      "         [[ 3.5666e-01]],\n",
      "\n",
      "         [[-1.0566e-01]],\n",
      "\n",
      "         [[-7.3155e-02]],\n",
      "\n",
      "         [[-1.1218e-02]],\n",
      "\n",
      "         [[-1.4539e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3689e-01]],\n",
      "\n",
      "         [[ 1.7239e-01]],\n",
      "\n",
      "         [[-3.4074e-01]],\n",
      "\n",
      "         [[ 1.4584e-01]],\n",
      "\n",
      "         [[ 1.3202e-01]],\n",
      "\n",
      "         [[ 2.3337e-01]],\n",
      "\n",
      "         [[-1.6866e-01]],\n",
      "\n",
      "         [[-1.1911e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7777e-01]],\n",
      "\n",
      "         [[-3.5953e-01]],\n",
      "\n",
      "         [[-2.5459e-01]],\n",
      "\n",
      "         [[-1.6089e-01]],\n",
      "\n",
      "         [[-5.4805e-01]],\n",
      "\n",
      "         [[ 1.3186e-01]],\n",
      "\n",
      "         [[-1.8549e-01]],\n",
      "\n",
      "         [[ 2.3433e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4306e-02]],\n",
      "\n",
      "         [[ 6.1251e-02]],\n",
      "\n",
      "         [[ 2.7205e-01]],\n",
      "\n",
      "         [[-1.2796e-01]],\n",
      "\n",
      "         [[-1.6958e-02]],\n",
      "\n",
      "         [[-3.8068e-02]],\n",
      "\n",
      "         [[ 5.3462e-02]],\n",
      "\n",
      "         [[-9.2999e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.1016e-02]],\n",
      "\n",
      "         [[-1.7640e-01]],\n",
      "\n",
      "         [[ 1.3023e-01]],\n",
      "\n",
      "         [[ 1.3153e-01]],\n",
      "\n",
      "         [[ 1.6536e-02]],\n",
      "\n",
      "         [[ 2.8721e-02]],\n",
      "\n",
      "         [[-1.1009e-01]],\n",
      "\n",
      "         [[ 2.1350e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2998e-01]],\n",
      "\n",
      "         [[ 5.8224e-01]],\n",
      "\n",
      "         [[ 3.0347e-01]],\n",
      "\n",
      "         [[-3.3323e-01]],\n",
      "\n",
      "         [[ 4.9579e-02]],\n",
      "\n",
      "         [[ 2.1599e-02]],\n",
      "\n",
      "         [[ 2.5036e-01]],\n",
      "\n",
      "         [[ 3.6305e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7620e-01]],\n",
      "\n",
      "         [[ 4.8574e-01]],\n",
      "\n",
      "         [[-6.7856e-02]],\n",
      "\n",
      "         [[ 1.6677e-01]],\n",
      "\n",
      "         [[ 1.9764e-01]],\n",
      "\n",
      "         [[-2.2054e-02]],\n",
      "\n",
      "         [[ 9.6285e-02]],\n",
      "\n",
      "         [[ 2.2715e-01]]]], device='cuda:0')}, 14: {'momentum_buffer': tensor([-0.0342, -0.0287,  0.0060, -0.2214,  0.1775,  0.0201,  0.0921, -0.1749,\n",
      "         0.1278, -0.0066, -0.0211, -0.0187, -0.1419, -0.0740,  0.4908,  0.0038],\n",
      "       device='cuda:0')}, 15: {'momentum_buffer': tensor([ 0.0033, -0.0138, -0.0238,  0.3118,  0.1328, -0.0181,  0.1155,  0.1530,\n",
      "         0.2692, -0.0160, -0.0115,  0.0206,  0.1514,  0.1344, -0.5418,  0.1076],\n",
      "       device='cuda:0')}, 16: {'momentum_buffer': tensor([[[[-5.8336e-02],\n",
      "          [ 4.4627e-03],\n",
      "          [-1.4822e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6666e-01],\n",
      "          [ 2.0621e-02],\n",
      "          [ 9.1927e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1802e-01],\n",
      "          [ 8.2959e-02],\n",
      "          [ 4.8423e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6476e-01],\n",
      "          [-7.1472e-01],\n",
      "          [-1.2574e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9422e-01],\n",
      "          [-1.7994e-01],\n",
      "          [-5.7471e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9187e-02],\n",
      "          [ 1.2096e-01],\n",
      "          [ 1.5925e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8941e-02],\n",
      "          [-1.5357e-02],\n",
      "          [-5.5229e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8234e-01],\n",
      "          [-1.6784e-01],\n",
      "          [ 6.0571e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4090e-01],\n",
      "          [ 4.1814e-01],\n",
      "          [ 2.6655e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1750e-01],\n",
      "          [-2.9134e-01],\n",
      "          [ 1.4043e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1524e-02],\n",
      "          [-1.2861e-01],\n",
      "          [ 3.8806e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.2570e-01],\n",
      "          [ 8.8508e-02],\n",
      "          [ 3.8455e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0277e-01],\n",
      "          [-2.0178e-01],\n",
      "          [-1.6752e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4784e-02],\n",
      "          [ 5.8984e-02],\n",
      "          [-1.7806e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5775e-02],\n",
      "          [ 7.3697e-04],\n",
      "          [ 5.2160e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7039e-02],\n",
      "          [ 3.5424e-02],\n",
      "          [-1.9044e-01]]]], device='cuda:0')}, 17: {'momentum_buffer': tensor([-0.0412,  0.0339,  0.0800, -0.2469,  0.0472,  0.3449,  0.1943, -0.1037,\n",
      "        -0.0232,  0.0212, -0.1220,  0.1519,  0.2191, -0.1390,  0.0554, -0.1116,\n",
      "         0.6411,  0.3436, -0.1389, -0.1524, -0.0442, -0.2999,  0.3056,  0.4219,\n",
      "         0.3401, -0.1895,  0.0685,  0.1820, -0.1591,  0.0578,  0.6775,  0.2899,\n",
      "         0.2735,  0.2713,  0.1169, -0.3249,  0.0427, -0.2870, -0.0606, -0.1404,\n",
      "        -0.5032, -0.1010, -0.0521, -0.5962,  0.2366, -0.7468,  0.5903, -0.0275],\n",
      "       device='cuda:0')}, 18: {'momentum_buffer': tensor([ 0.1138, -0.1445,  0.1268, -0.0747, -0.0424, -0.1323,  0.0516,  0.0225,\n",
      "        -0.0599,  0.0577, -0.2123, -0.0045,  0.2075, -0.0684,  0.0014,  0.0124,\n",
      "        -0.0117,  0.3466,  0.0636,  0.1071, -0.0021, -0.1448,  0.1910, -0.1642,\n",
      "         0.3337, -0.0443,  0.0886, -0.0252,  0.1868,  0.0084,  0.0250,  0.0576,\n",
      "         0.0918,  0.1227, -0.2857, -0.0824,  0.0040, -0.2438, -0.1174, -0.1331,\n",
      "        -0.0422, -0.0368, -0.0538, -0.3993,  0.3794, -0.3432,  0.2815, -0.1121],\n",
      "       device='cuda:0')}, 19: {'momentum_buffer': tensor([[[[-9.4309e-02, -2.2311e-02,  7.2882e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0734e-09,  2.5377e-09, -2.1759e-09]]],\n",
      "\n",
      "\n",
      "        [[[-1.7610e-01,  1.0047e-01,  2.2698e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2019e-02,  1.6261e-01,  9.6609e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1805e-02, -2.5210e-02,  2.2520e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.0583e-01, -2.5472e-01, -1.9482e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9325e-06,  4.6867e-06,  1.2329e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1595e-01,  2.0133e-01,  1.0609e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7957e-01, -5.0381e-01, -3.8325e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7702e-06, -3.0707e-06, -2.6392e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.1110e-01, -4.9057e-02, -1.3090e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1631e-01, -1.7231e-01, -9.2786e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7517e-01,  3.3297e-02, -1.7064e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0089e-01, -5.7318e-02, -1.3750e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6433e-01,  3.2237e-01,  2.6382e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7346e-03, -1.4372e-01, -4.2642e-02]]]], device='cuda:0')}, 20: {'momentum_buffer': tensor([ 6.6667e-02, -1.4721e-10,  9.6655e-02, -6.2998e-02,  6.4403e-02,\n",
      "        -1.5122e-01,  8.5646e-08, -7.2404e-02, -8.5130e-02, -4.4019e-09,\n",
      "        -1.4831e-01, -1.4266e-02, -3.7966e-01, -7.6555e-02,  1.2522e-01,\n",
      "        -7.3352e-02], device='cuda:0')}, 21: {'momentum_buffer': tensor([ 1.4463e-01, -1.4416e-09, -7.3245e-02, -2.7651e-02,  6.9576e-02,\n",
      "         2.4976e-02, -3.9535e-06,  7.9855e-02, -1.6300e-01, -5.2565e-07,\n",
      "        -2.8343e-01,  5.2490e-02,  2.9383e-02, -8.2500e-02, -1.3167e-01,\n",
      "         4.6857e-02], device='cuda:0')}, 22: {'momentum_buffer': tensor([[[[ 2.2617e-02]],\n",
      "\n",
      "         [[-1.6041e-09]],\n",
      "\n",
      "         [[ 1.6645e-02]],\n",
      "\n",
      "         [[-4.6538e-02]],\n",
      "\n",
      "         [[-7.2365e-02]],\n",
      "\n",
      "         [[ 3.6013e-03]],\n",
      "\n",
      "         [[ 2.8063e-06]],\n",
      "\n",
      "         [[-5.0122e-02]],\n",
      "\n",
      "         [[ 2.8717e-02]],\n",
      "\n",
      "         [[-9.9714e-07]],\n",
      "\n",
      "         [[ 3.0572e-02]],\n",
      "\n",
      "         [[ 8.9214e-04]],\n",
      "\n",
      "         [[-2.8495e-02]],\n",
      "\n",
      "         [[ 4.7746e-02]],\n",
      "\n",
      "         [[-5.7542e-02]],\n",
      "\n",
      "         [[ 4.4102e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8417e-02]],\n",
      "\n",
      "         [[ 1.9585e-09]],\n",
      "\n",
      "         [[ 5.3918e-02]],\n",
      "\n",
      "         [[-9.9266e-02]],\n",
      "\n",
      "         [[-3.5159e-02]],\n",
      "\n",
      "         [[-2.8563e-03]],\n",
      "\n",
      "         [[-7.1915e-06]],\n",
      "\n",
      "         [[-8.4425e-02]],\n",
      "\n",
      "         [[-1.4228e-01]],\n",
      "\n",
      "         [[ 1.0697e-06]],\n",
      "\n",
      "         [[ 2.1269e-02]],\n",
      "\n",
      "         [[-3.1026e-02]],\n",
      "\n",
      "         [[-1.1301e-01]],\n",
      "\n",
      "         [[-4.8351e-02]],\n",
      "\n",
      "         [[ 1.4751e-03]],\n",
      "\n",
      "         [[-6.9211e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.5770e-02]],\n",
      "\n",
      "         [[ 1.1762e-09]],\n",
      "\n",
      "         [[-3.9939e-02]],\n",
      "\n",
      "         [[ 4.6856e-02]],\n",
      "\n",
      "         [[-7.3548e-02]],\n",
      "\n",
      "         [[-1.9326e-02]],\n",
      "\n",
      "         [[-9.1087e-07]],\n",
      "\n",
      "         [[-2.1587e-02]],\n",
      "\n",
      "         [[-3.6836e-02]],\n",
      "\n",
      "         [[ 1.1869e-06]],\n",
      "\n",
      "         [[ 6.7382e-02]],\n",
      "\n",
      "         [[-2.0782e-01]],\n",
      "\n",
      "         [[-1.8213e-04]],\n",
      "\n",
      "         [[-3.2161e-02]],\n",
      "\n",
      "         [[ 1.4453e-01]],\n",
      "\n",
      "         [[ 2.4962e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.9913e-02]],\n",
      "\n",
      "         [[ 1.2885e-09]],\n",
      "\n",
      "         [[-3.8235e-02]],\n",
      "\n",
      "         [[ 2.8554e-02]],\n",
      "\n",
      "         [[ 8.4381e-03]],\n",
      "\n",
      "         [[ 2.1001e-02]],\n",
      "\n",
      "         [[ 3.1876e-06]],\n",
      "\n",
      "         [[ 1.4379e-01]],\n",
      "\n",
      "         [[ 1.9435e-01]],\n",
      "\n",
      "         [[-2.7756e-06]],\n",
      "\n",
      "         [[ 1.9501e-02]],\n",
      "\n",
      "         [[-4.5042e-02]],\n",
      "\n",
      "         [[ 1.6753e-01]],\n",
      "\n",
      "         [[ 8.2312e-03]],\n",
      "\n",
      "         [[-2.1452e-02]],\n",
      "\n",
      "         [[-2.8791e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0439e-01]],\n",
      "\n",
      "         [[-1.8698e-09]],\n",
      "\n",
      "         [[-6.1445e-02]],\n",
      "\n",
      "         [[ 1.8265e-02]],\n",
      "\n",
      "         [[ 2.0065e-02]],\n",
      "\n",
      "         [[-1.1575e-01]],\n",
      "\n",
      "         [[-4.0626e-06]],\n",
      "\n",
      "         [[-1.3134e-01]],\n",
      "\n",
      "         [[-7.8591e-02]],\n",
      "\n",
      "         [[-1.7426e-08]],\n",
      "\n",
      "         [[-1.0242e-02]],\n",
      "\n",
      "         [[ 6.1597e-03]],\n",
      "\n",
      "         [[ 3.2397e-02]],\n",
      "\n",
      "         [[-6.4164e-02]],\n",
      "\n",
      "         [[-9.0593e-02]],\n",
      "\n",
      "         [[-1.5075e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2522e-02]],\n",
      "\n",
      "         [[ 2.5339e-10]],\n",
      "\n",
      "         [[-9.4512e-02]],\n",
      "\n",
      "         [[ 1.0421e-01]],\n",
      "\n",
      "         [[-9.3433e-02]],\n",
      "\n",
      "         [[-1.4553e-01]],\n",
      "\n",
      "         [[ 1.9070e-06]],\n",
      "\n",
      "         [[ 3.0652e-02]],\n",
      "\n",
      "         [[ 4.2473e-02]],\n",
      "\n",
      "         [[ 6.9851e-07]],\n",
      "\n",
      "         [[ 1.6506e-01]],\n",
      "\n",
      "         [[ 5.2037e-02]],\n",
      "\n",
      "         [[-2.1973e-02]],\n",
      "\n",
      "         [[ 1.0930e-01]],\n",
      "\n",
      "         [[ 1.1369e-01]],\n",
      "\n",
      "         [[ 2.7168e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2507e-02]],\n",
      "\n",
      "         [[-2.1072e-09]],\n",
      "\n",
      "         [[-3.5177e-02]],\n",
      "\n",
      "         [[-3.7307e-02]],\n",
      "\n",
      "         [[-4.9941e-02]],\n",
      "\n",
      "         [[ 4.5968e-02]],\n",
      "\n",
      "         [[ 7.4150e-07]],\n",
      "\n",
      "         [[-8.1862e-02]],\n",
      "\n",
      "         [[-1.5303e-01]],\n",
      "\n",
      "         [[ 1.7630e-06]],\n",
      "\n",
      "         [[ 3.1780e-02]],\n",
      "\n",
      "         [[ 6.4772e-03]],\n",
      "\n",
      "         [[-1.5080e-01]],\n",
      "\n",
      "         [[-2.9466e-02]],\n",
      "\n",
      "         [[-6.1806e-02]],\n",
      "\n",
      "         [[ 1.1875e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2951e-01]],\n",
      "\n",
      "         [[ 1.8623e-09]],\n",
      "\n",
      "         [[ 3.7501e-02]],\n",
      "\n",
      "         [[ 1.5898e-02]],\n",
      "\n",
      "         [[-4.3597e-02]],\n",
      "\n",
      "         [[-9.3383e-02]],\n",
      "\n",
      "         [[ 1.4773e-07]],\n",
      "\n",
      "         [[-3.5348e-02]],\n",
      "\n",
      "         [[-6.3354e-02]],\n",
      "\n",
      "         [[ 1.6375e-06]],\n",
      "\n",
      "         [[ 8.0469e-02]],\n",
      "\n",
      "         [[-1.9304e-01]],\n",
      "\n",
      "         [[-1.3996e-01]],\n",
      "\n",
      "         [[-2.2740e-02]],\n",
      "\n",
      "         [[-9.0008e-02]],\n",
      "\n",
      "         [[ 3.6852e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6345e-02]],\n",
      "\n",
      "         [[-1.4518e-09]],\n",
      "\n",
      "         [[ 5.3973e-02]],\n",
      "\n",
      "         [[ 4.4865e-03]],\n",
      "\n",
      "         [[-1.5232e-02]],\n",
      "\n",
      "         [[ 1.2184e-01]],\n",
      "\n",
      "         [[ 2.3703e-06]],\n",
      "\n",
      "         [[ 7.6768e-02]],\n",
      "\n",
      "         [[ 9.8071e-02]],\n",
      "\n",
      "         [[-6.6433e-07]],\n",
      "\n",
      "         [[ 8.1388e-02]],\n",
      "\n",
      "         [[ 9.6318e-02]],\n",
      "\n",
      "         [[ 6.0351e-02]],\n",
      "\n",
      "         [[ 3.7277e-02]],\n",
      "\n",
      "         [[ 3.4902e-02]],\n",
      "\n",
      "         [[ 2.3012e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9967e-02]],\n",
      "\n",
      "         [[-1.7944e-10]],\n",
      "\n",
      "         [[ 1.8549e-02]],\n",
      "\n",
      "         [[ 9.5363e-02]],\n",
      "\n",
      "         [[ 5.0165e-02]],\n",
      "\n",
      "         [[ 1.6244e-01]],\n",
      "\n",
      "         [[-9.7240e-07]],\n",
      "\n",
      "         [[ 6.3343e-03]],\n",
      "\n",
      "         [[-1.2306e-02]],\n",
      "\n",
      "         [[ 8.3438e-07]],\n",
      "\n",
      "         [[ 1.6223e-01]],\n",
      "\n",
      "         [[ 9.0119e-03]],\n",
      "\n",
      "         [[-3.7935e-02]],\n",
      "\n",
      "         [[ 2.1694e-02]],\n",
      "\n",
      "         [[ 1.1622e-01]],\n",
      "\n",
      "         [[ 4.7571e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7468e-02]],\n",
      "\n",
      "         [[-2.3779e-09]],\n",
      "\n",
      "         [[-1.4325e-01]],\n",
      "\n",
      "         [[-8.5159e-02]],\n",
      "\n",
      "         [[ 7.0657e-03]],\n",
      "\n",
      "         [[-1.7706e-01]],\n",
      "\n",
      "         [[-8.4076e-07]],\n",
      "\n",
      "         [[-1.2791e-01]],\n",
      "\n",
      "         [[-1.2083e-01]],\n",
      "\n",
      "         [[ 9.8757e-07]],\n",
      "\n",
      "         [[-1.0852e-01]],\n",
      "\n",
      "         [[-1.6907e-01]],\n",
      "\n",
      "         [[-1.9919e-03]],\n",
      "\n",
      "         [[-6.9525e-02]],\n",
      "\n",
      "         [[-1.4298e-02]],\n",
      "\n",
      "         [[-1.0981e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7417e-01]],\n",
      "\n",
      "         [[ 1.1005e-09]],\n",
      "\n",
      "         [[ 5.5534e-02]],\n",
      "\n",
      "         [[ 7.2965e-02]],\n",
      "\n",
      "         [[ 1.0621e-01]],\n",
      "\n",
      "         [[-2.8438e-02]],\n",
      "\n",
      "         [[-5.1955e-06]],\n",
      "\n",
      "         [[ 1.9791e-01]],\n",
      "\n",
      "         [[ 1.1565e-01]],\n",
      "\n",
      "         [[ 6.1687e-07]],\n",
      "\n",
      "         [[ 4.4707e-02]],\n",
      "\n",
      "         [[ 2.0462e-01]],\n",
      "\n",
      "         [[ 2.5421e-01]],\n",
      "\n",
      "         [[ 1.0466e-01]],\n",
      "\n",
      "         [[ 2.4924e-01]],\n",
      "\n",
      "         [[ 1.0623e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4696e-01]],\n",
      "\n",
      "         [[-6.5039e-10]],\n",
      "\n",
      "         [[-6.1682e-02]],\n",
      "\n",
      "         [[-1.0596e-01]],\n",
      "\n",
      "         [[-8.2763e-02]],\n",
      "\n",
      "         [[-6.6888e-03]],\n",
      "\n",
      "         [[-2.6246e-06]],\n",
      "\n",
      "         [[-7.2635e-02]],\n",
      "\n",
      "         [[-6.4744e-02]],\n",
      "\n",
      "         [[-3.7080e-07]],\n",
      "\n",
      "         [[-6.3946e-02]],\n",
      "\n",
      "         [[-1.5344e-01]],\n",
      "\n",
      "         [[-1.0456e-01]],\n",
      "\n",
      "         [[-1.3665e-01]],\n",
      "\n",
      "         [[-1.9049e-01]],\n",
      "\n",
      "         [[-3.5702e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7423e-02]],\n",
      "\n",
      "         [[-3.4211e-09]],\n",
      "\n",
      "         [[-4.3671e-02]],\n",
      "\n",
      "         [[ 1.1077e-02]],\n",
      "\n",
      "         [[ 1.1240e-01]],\n",
      "\n",
      "         [[ 3.6032e-02]],\n",
      "\n",
      "         [[ 5.1199e-07]],\n",
      "\n",
      "         [[-2.2444e-02]],\n",
      "\n",
      "         [[ 8.0147e-03]],\n",
      "\n",
      "         [[ 2.2949e-06]],\n",
      "\n",
      "         [[-4.0818e-02]],\n",
      "\n",
      "         [[ 4.8502e-02]],\n",
      "\n",
      "         [[ 1.1171e-01]],\n",
      "\n",
      "         [[ 2.1241e-02]],\n",
      "\n",
      "         [[ 6.7371e-02]],\n",
      "\n",
      "         [[ 1.3976e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0843e-02]],\n",
      "\n",
      "         [[-1.0010e-09]],\n",
      "\n",
      "         [[-2.5975e-01]],\n",
      "\n",
      "         [[ 1.3838e-01]],\n",
      "\n",
      "         [[ 6.3984e-02]],\n",
      "\n",
      "         [[ 1.6625e-01]],\n",
      "\n",
      "         [[ 1.1196e-06]],\n",
      "\n",
      "         [[-6.1268e-03]],\n",
      "\n",
      "         [[ 5.8021e-02]],\n",
      "\n",
      "         [[-1.0380e-06]],\n",
      "\n",
      "         [[-6.5420e-02]],\n",
      "\n",
      "         [[ 1.5865e-01]],\n",
      "\n",
      "         [[-7.1393e-03]],\n",
      "\n",
      "         [[ 5.1104e-02]],\n",
      "\n",
      "         [[ 7.8099e-02]],\n",
      "\n",
      "         [[ 4.3507e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8807e-02]],\n",
      "\n",
      "         [[ 5.4843e-11]],\n",
      "\n",
      "         [[ 3.8494e-02]],\n",
      "\n",
      "         [[ 5.5711e-02]],\n",
      "\n",
      "         [[-4.7791e-02]],\n",
      "\n",
      "         [[-8.2489e-02]],\n",
      "\n",
      "         [[ 6.2894e-06]],\n",
      "\n",
      "         [[-1.1437e-03]],\n",
      "\n",
      "         [[-4.2596e-02]],\n",
      "\n",
      "         [[-1.9718e-06]],\n",
      "\n",
      "         [[ 6.2602e-02]],\n",
      "\n",
      "         [[ 1.1433e-02]],\n",
      "\n",
      "         [[-7.3441e-03]],\n",
      "\n",
      "         [[ 8.9113e-03]],\n",
      "\n",
      "         [[ 5.5999e-02]],\n",
      "\n",
      "         [[ 3.7837e-02]]]], device='cuda:0')}, 23: {'momentum_buffer': tensor([[[[-0.0443]],\n",
      "\n",
      "         [[-0.0720]],\n",
      "\n",
      "         [[-0.0058]],\n",
      "\n",
      "         [[ 0.0939]],\n",
      "\n",
      "         [[ 0.1747]],\n",
      "\n",
      "         [[ 0.2314]],\n",
      "\n",
      "         [[ 0.1252]],\n",
      "\n",
      "         [[ 0.1826]],\n",
      "\n",
      "         [[ 0.0160]],\n",
      "\n",
      "         [[-0.1642]],\n",
      "\n",
      "         [[-0.0900]],\n",
      "\n",
      "         [[ 0.2981]],\n",
      "\n",
      "         [[ 0.0379]],\n",
      "\n",
      "         [[ 0.1277]],\n",
      "\n",
      "         [[ 0.3784]],\n",
      "\n",
      "         [[ 0.5896]]],\n",
      "\n",
      "\n",
      "        [[[-0.0059]],\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[-0.0708]],\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[ 0.2826]],\n",
      "\n",
      "         [[ 0.1418]],\n",
      "\n",
      "         [[ 0.0373]],\n",
      "\n",
      "         [[-0.0142]],\n",
      "\n",
      "         [[ 0.0812]],\n",
      "\n",
      "         [[ 0.1345]],\n",
      "\n",
      "         [[-0.2918]],\n",
      "\n",
      "         [[-0.0407]],\n",
      "\n",
      "         [[-0.0674]],\n",
      "\n",
      "         [[-0.2288]],\n",
      "\n",
      "         [[-0.1366]],\n",
      "\n",
      "         [[ 0.0234]]],\n",
      "\n",
      "\n",
      "        [[[-0.0014]],\n",
      "\n",
      "         [[ 0.0224]],\n",
      "\n",
      "         [[ 0.0205]],\n",
      "\n",
      "         [[ 0.0760]],\n",
      "\n",
      "         [[ 0.0473]],\n",
      "\n",
      "         [[ 0.1301]],\n",
      "\n",
      "         [[ 0.0582]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[ 0.0843]],\n",
      "\n",
      "         [[-0.0617]],\n",
      "\n",
      "         [[-0.0031]],\n",
      "\n",
      "         [[-0.0171]],\n",
      "\n",
      "         [[-0.1245]],\n",
      "\n",
      "         [[-0.0733]],\n",
      "\n",
      "         [[-0.0008]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1516]],\n",
      "\n",
      "         [[ 0.0491]],\n",
      "\n",
      "         [[ 0.0373]],\n",
      "\n",
      "         [[-0.0333]],\n",
      "\n",
      "         [[ 0.0758]],\n",
      "\n",
      "         [[ 0.0774]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         [[-0.0675]],\n",
      "\n",
      "         [[ 0.0163]],\n",
      "\n",
      "         [[ 0.0730]],\n",
      "\n",
      "         [[ 0.1487]],\n",
      "\n",
      "         [[ 0.1983]],\n",
      "\n",
      "         [[-0.1369]],\n",
      "\n",
      "         [[ 0.0873]],\n",
      "\n",
      "         [[ 0.0548]],\n",
      "\n",
      "         [[ 0.2756]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.0318]],\n",
      "\n",
      "         [[-0.0602]],\n",
      "\n",
      "         [[ 0.0510]],\n",
      "\n",
      "         [[ 0.0170]],\n",
      "\n",
      "         [[ 0.0559]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[-0.0122]],\n",
      "\n",
      "         [[-0.1752]],\n",
      "\n",
      "         [[-0.1487]],\n",
      "\n",
      "         [[-0.0207]],\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         [[-0.0453]],\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         [[-0.1820]]],\n",
      "\n",
      "\n",
      "        [[[-0.0406]],\n",
      "\n",
      "         [[-0.0017]],\n",
      "\n",
      "         [[-0.0062]],\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         [[ 0.0317]],\n",
      "\n",
      "         [[ 0.0074]],\n",
      "\n",
      "         [[ 0.0748]],\n",
      "\n",
      "         [[ 0.0130]],\n",
      "\n",
      "         [[-0.1125]],\n",
      "\n",
      "         [[ 0.1257]],\n",
      "\n",
      "         [[-0.0697]],\n",
      "\n",
      "         [[-0.0582]],\n",
      "\n",
      "         [[-0.0030]],\n",
      "\n",
      "         [[ 0.0803]],\n",
      "\n",
      "         [[ 0.0175]],\n",
      "\n",
      "         [[ 0.0776]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0507]],\n",
      "\n",
      "         [[ 0.1382]],\n",
      "\n",
      "         [[-0.0358]],\n",
      "\n",
      "         [[-0.1000]],\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         [[-0.0319]],\n",
      "\n",
      "         [[ 0.0175]],\n",
      "\n",
      "         [[-0.1225]],\n",
      "\n",
      "         [[ 0.0178]],\n",
      "\n",
      "         [[ 0.0343]],\n",
      "\n",
      "         [[-0.2132]],\n",
      "\n",
      "         [[-0.0537]],\n",
      "\n",
      "         [[ 0.0929]],\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0244]],\n",
      "\n",
      "         [[-0.0141]],\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         [[-0.0460]],\n",
      "\n",
      "         [[ 0.1202]],\n",
      "\n",
      "         [[ 0.0801]],\n",
      "\n",
      "         [[ 0.1157]],\n",
      "\n",
      "         [[ 0.0388]],\n",
      "\n",
      "         [[-0.1095]],\n",
      "\n",
      "         [[-0.0843]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         [[ 0.0580]],\n",
      "\n",
      "         [[-0.1072]],\n",
      "\n",
      "         [[-0.0282]],\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[-0.0166]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1219]],\n",
      "\n",
      "         [[-0.0572]],\n",
      "\n",
      "         [[ 0.1372]],\n",
      "\n",
      "         [[ 0.0505]],\n",
      "\n",
      "         [[ 0.0716]],\n",
      "\n",
      "         [[ 0.1898]],\n",
      "\n",
      "         [[-0.0070]],\n",
      "\n",
      "         [[-0.3827]],\n",
      "\n",
      "         [[ 0.2745]],\n",
      "\n",
      "         [[-0.0967]],\n",
      "\n",
      "         [[-0.0647]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         [[ 0.0053]],\n",
      "\n",
      "         [[-0.1033]],\n",
      "\n",
      "         [[-0.1183]],\n",
      "\n",
      "         [[ 0.0516]]],\n",
      "\n",
      "\n",
      "        [[[-0.0606]],\n",
      "\n",
      "         [[ 0.1282]],\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         [[-0.0918]],\n",
      "\n",
      "         [[-0.0097]],\n",
      "\n",
      "         [[-0.0275]],\n",
      "\n",
      "         [[ 0.0172]],\n",
      "\n",
      "         [[-0.1306]],\n",
      "\n",
      "         [[-0.1356]],\n",
      "\n",
      "         [[ 0.1994]],\n",
      "\n",
      "         [[-0.1494]],\n",
      "\n",
      "         [[ 0.0602]],\n",
      "\n",
      "         [[ 0.0208]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         [[-0.1618]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0302]],\n",
      "\n",
      "         [[ 0.0974]],\n",
      "\n",
      "         [[-0.0880]],\n",
      "\n",
      "         [[ 0.1182]],\n",
      "\n",
      "         [[-0.0203]],\n",
      "\n",
      "         [[-0.0706]],\n",
      "\n",
      "         [[-0.0842]],\n",
      "\n",
      "         [[ 0.0600]],\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.2055]],\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         [[-0.0859]],\n",
      "\n",
      "         [[-0.0911]],\n",
      "\n",
      "         [[ 0.0257]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0153]],\n",
      "\n",
      "         [[ 0.1530]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[ 0.0409]],\n",
      "\n",
      "         [[ 0.0744]],\n",
      "\n",
      "         [[-0.0861]],\n",
      "\n",
      "         [[ 0.0175]],\n",
      "\n",
      "         [[ 0.2075]],\n",
      "\n",
      "         [[-0.1730]],\n",
      "\n",
      "         [[-0.0917]],\n",
      "\n",
      "         [[ 0.1152]],\n",
      "\n",
      "         [[ 0.1397]],\n",
      "\n",
      "         [[-0.0899]],\n",
      "\n",
      "         [[ 0.1199]],\n",
      "\n",
      "         [[ 0.1397]],\n",
      "\n",
      "         [[ 0.1840]]],\n",
      "\n",
      "\n",
      "        [[[-0.0507]],\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         [[ 0.1379]],\n",
      "\n",
      "         [[-0.0187]],\n",
      "\n",
      "         [[ 0.0490]],\n",
      "\n",
      "         [[ 0.0834]],\n",
      "\n",
      "         [[ 0.1031]],\n",
      "\n",
      "         [[ 0.0531]],\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         [[-0.0826]],\n",
      "\n",
      "         [[-0.0236]],\n",
      "\n",
      "         [[-0.0025]],\n",
      "\n",
      "         [[-0.0330]],\n",
      "\n",
      "         [[-0.0837]],\n",
      "\n",
      "         [[-0.0639]],\n",
      "\n",
      "         [[ 0.2396]]],\n",
      "\n",
      "\n",
      "        [[[-0.0737]],\n",
      "\n",
      "         [[-0.0982]],\n",
      "\n",
      "         [[-0.0070]],\n",
      "\n",
      "         [[-0.0920]],\n",
      "\n",
      "         [[ 0.0728]],\n",
      "\n",
      "         [[-0.0225]],\n",
      "\n",
      "         [[ 0.0575]],\n",
      "\n",
      "         [[-0.0503]],\n",
      "\n",
      "         [[-0.0061]],\n",
      "\n",
      "         [[ 0.1807]],\n",
      "\n",
      "         [[-0.0528]],\n",
      "\n",
      "         [[ 0.0823]],\n",
      "\n",
      "         [[-0.0368]],\n",
      "\n",
      "         [[ 0.1774]],\n",
      "\n",
      "         [[ 0.0277]],\n",
      "\n",
      "         [[-0.0380]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0100]],\n",
      "\n",
      "         [[-0.1127]],\n",
      "\n",
      "         [[ 0.0116]],\n",
      "\n",
      "         [[ 0.0511]],\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[ 0.0940]],\n",
      "\n",
      "         [[ 0.0815]],\n",
      "\n",
      "         [[-0.0406]],\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[-0.1494]],\n",
      "\n",
      "         [[ 0.0951]],\n",
      "\n",
      "         [[ 0.2385]],\n",
      "\n",
      "         [[ 0.0624]],\n",
      "\n",
      "         [[ 0.1669]],\n",
      "\n",
      "         [[ 0.1656]],\n",
      "\n",
      "         [[-0.2269]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0503]],\n",
      "\n",
      "         [[-0.1032]],\n",
      "\n",
      "         [[-0.0857]],\n",
      "\n",
      "         [[-0.0186]],\n",
      "\n",
      "         [[-0.1152]],\n",
      "\n",
      "         [[ 0.1820]],\n",
      "\n",
      "         [[-0.0110]],\n",
      "\n",
      "         [[ 0.0016]],\n",
      "\n",
      "         [[ 0.0914]],\n",
      "\n",
      "         [[ 0.0135]],\n",
      "\n",
      "         [[-0.0213]],\n",
      "\n",
      "         [[-0.1239]],\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         [[-0.2316]],\n",
      "\n",
      "         [[-0.0750]],\n",
      "\n",
      "         [[ 0.1018]]],\n",
      "\n",
      "\n",
      "        [[[-0.3093]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[-0.0251]],\n",
      "\n",
      "         [[-0.0770]],\n",
      "\n",
      "         [[-0.1386]],\n",
      "\n",
      "         [[ 0.0050]],\n",
      "\n",
      "         [[ 0.1025]],\n",
      "\n",
      "         [[ 0.1904]],\n",
      "\n",
      "         [[-0.2302]],\n",
      "\n",
      "         [[ 0.0722]],\n",
      "\n",
      "         [[ 0.0794]],\n",
      "\n",
      "         [[ 0.0099]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         [[ 0.1827]],\n",
      "\n",
      "         [[ 0.2029]],\n",
      "\n",
      "         [[-0.1940]]],\n",
      "\n",
      "\n",
      "        [[[-0.1061]],\n",
      "\n",
      "         [[-0.1102]],\n",
      "\n",
      "         [[ 0.3237]],\n",
      "\n",
      "         [[ 0.1213]],\n",
      "\n",
      "         [[-0.0814]],\n",
      "\n",
      "         [[-0.0313]],\n",
      "\n",
      "         [[-0.2536]],\n",
      "\n",
      "         [[-0.1019]],\n",
      "\n",
      "         [[ 0.0125]],\n",
      "\n",
      "         [[ 0.1117]],\n",
      "\n",
      "         [[-0.0869]],\n",
      "\n",
      "         [[ 0.4808]],\n",
      "\n",
      "         [[ 0.2149]],\n",
      "\n",
      "         [[-0.4746]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         [[-0.1117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0479]],\n",
      "\n",
      "         [[ 0.0695]],\n",
      "\n",
      "         [[-0.0450]],\n",
      "\n",
      "         [[-0.1354]],\n",
      "\n",
      "         [[-0.1707]],\n",
      "\n",
      "         [[ 0.1346]],\n",
      "\n",
      "         [[ 0.0464]],\n",
      "\n",
      "         [[-0.0729]],\n",
      "\n",
      "         [[-0.0347]],\n",
      "\n",
      "         [[ 0.0821]],\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         [[-0.0722]],\n",
      "\n",
      "         [[-0.0888]],\n",
      "\n",
      "         [[-0.0260]],\n",
      "\n",
      "         [[-0.0797]],\n",
      "\n",
      "         [[ 0.0571]]],\n",
      "\n",
      "\n",
      "        [[[-0.0114]],\n",
      "\n",
      "         [[-0.0705]],\n",
      "\n",
      "         [[ 0.0601]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         [[-0.0265]],\n",
      "\n",
      "         [[-0.0407]],\n",
      "\n",
      "         [[-0.0586]],\n",
      "\n",
      "         [[-0.0707]],\n",
      "\n",
      "         [[ 0.0348]],\n",
      "\n",
      "         [[-0.1219]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[ 0.0932]],\n",
      "\n",
      "         [[ 0.0487]],\n",
      "\n",
      "         [[-0.2902]],\n",
      "\n",
      "         [[-0.2128]],\n",
      "\n",
      "         [[-0.1847]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0170]],\n",
      "\n",
      "         [[ 0.1843]],\n",
      "\n",
      "         [[-0.0349]],\n",
      "\n",
      "         [[ 0.0702]],\n",
      "\n",
      "         [[-0.1193]],\n",
      "\n",
      "         [[ 0.0618]],\n",
      "\n",
      "         [[-0.1638]],\n",
      "\n",
      "         [[ 0.2808]],\n",
      "\n",
      "         [[-0.0636]],\n",
      "\n",
      "         [[ 0.0665]],\n",
      "\n",
      "         [[ 0.0355]],\n",
      "\n",
      "         [[-0.0758]],\n",
      "\n",
      "         [[ 0.2619]],\n",
      "\n",
      "         [[ 0.1930]],\n",
      "\n",
      "         [[ 0.0060]],\n",
      "\n",
      "         [[-0.0504]]],\n",
      "\n",
      "\n",
      "        [[[-0.0865]],\n",
      "\n",
      "         [[-0.2809]],\n",
      "\n",
      "         [[-0.1137]],\n",
      "\n",
      "         [[-0.1137]],\n",
      "\n",
      "         [[ 0.0704]],\n",
      "\n",
      "         [[-0.1706]],\n",
      "\n",
      "         [[-0.0450]],\n",
      "\n",
      "         [[ 0.2181]],\n",
      "\n",
      "         [[-0.0030]],\n",
      "\n",
      "         [[-0.1847]],\n",
      "\n",
      "         [[-0.0868]],\n",
      "\n",
      "         [[-0.0116]],\n",
      "\n",
      "         [[-0.1447]],\n",
      "\n",
      "         [[-0.1120]],\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         [[-0.0078]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1294]],\n",
      "\n",
      "         [[ 0.0965]],\n",
      "\n",
      "         [[-0.1054]],\n",
      "\n",
      "         [[ 0.2164]],\n",
      "\n",
      "         [[ 0.0330]],\n",
      "\n",
      "         [[ 0.6330]],\n",
      "\n",
      "         [[ 0.1129]],\n",
      "\n",
      "         [[-0.1049]],\n",
      "\n",
      "         [[ 0.2004]],\n",
      "\n",
      "         [[ 0.2272]],\n",
      "\n",
      "         [[ 0.0507]],\n",
      "\n",
      "         [[-0.0956]],\n",
      "\n",
      "         [[ 0.1193]],\n",
      "\n",
      "         [[-0.2472]],\n",
      "\n",
      "         [[-0.3346]],\n",
      "\n",
      "         [[-0.5449]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0745]],\n",
      "\n",
      "         [[ 0.0727]],\n",
      "\n",
      "         [[ 0.0707]],\n",
      "\n",
      "         [[ 0.0478]],\n",
      "\n",
      "         [[-0.1612]],\n",
      "\n",
      "         [[ 0.1421]],\n",
      "\n",
      "         [[-0.1466]],\n",
      "\n",
      "         [[-0.0500]],\n",
      "\n",
      "         [[ 0.0733]],\n",
      "\n",
      "         [[-0.1574]],\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         [[-0.0497]],\n",
      "\n",
      "         [[ 0.0959]],\n",
      "\n",
      "         [[-0.1207]],\n",
      "\n",
      "         [[-0.1012]],\n",
      "\n",
      "         [[-0.0026]]]], device='cuda:0')}, 24: {'momentum_buffer': tensor([ 0.0782, -0.2028,  0.0120,  0.1243, -0.0163, -0.0218, -0.0333, -0.0587,\n",
      "         0.1790, -0.0014, -0.1132,  0.0405, -0.0016, -0.0238, -0.0517,  0.0743,\n",
      "        -0.0207,  0.0668,  0.0207,  0.3228,  0.0017,  0.0952,  0.0759, -0.0470],\n",
      "       device='cuda:0')}, 25: {'momentum_buffer': tensor([ 0.0315,  0.1682,  0.0757,  0.1431, -0.0516,  0.0216, -0.0275,  0.0015,\n",
      "         0.1295, -0.0231,  0.1138,  0.1015,  0.0120,  0.0024,  0.0286, -0.1781,\n",
      "        -0.0240, -0.1531,  0.1701,  0.0740,  0.0139,  0.1810,  0.0009, -0.0418],\n",
      "       device='cuda:0')}, 26: {'momentum_buffer': tensor([[[[ 4.7136e-01],\n",
      "          [-4.0587e-02],\n",
      "          [ 6.9389e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0500e-01],\n",
      "          [ 3.8378e-02],\n",
      "          [-2.1412e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5911e-02],\n",
      "          [-2.1658e-02],\n",
      "          [-5.9049e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0631e-02],\n",
      "          [-4.3236e-02],\n",
      "          [-1.3492e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0385e-01],\n",
      "          [ 1.3236e-01],\n",
      "          [-1.7729e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5385e-02],\n",
      "          [-1.1327e-01],\n",
      "          [ 3.3216e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2788e-02],\n",
      "          [ 2.2499e-01],\n",
      "          [-8.1720e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3238e-01],\n",
      "          [ 8.2724e-02],\n",
      "          [-1.7211e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8336e-03],\n",
      "          [-6.2832e-02],\n",
      "          [ 1.8595e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5184e-01],\n",
      "          [ 1.2401e-01],\n",
      "          [ 5.0068e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7192e-02],\n",
      "          [ 6.3006e-02],\n",
      "          [ 1.3336e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7793e-02],\n",
      "          [-1.6033e-02],\n",
      "          [ 5.5846e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8581e-02],\n",
      "          [ 2.6311e-01],\n",
      "          [ 7.7260e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6522e-01],\n",
      "          [-4.5182e-02],\n",
      "          [-8.2565e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2862e-01],\n",
      "          [ 7.9621e-02],\n",
      "          [ 8.9516e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3329e-02],\n",
      "          [ 2.2130e-01],\n",
      "          [-1.0499e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7989e-02],\n",
      "          [ 7.1476e-02],\n",
      "          [ 3.9643e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7026e-02],\n",
      "          [-2.6606e-01],\n",
      "          [-2.8338e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0601e-02],\n",
      "          [-9.0371e-02],\n",
      "          [ 1.8927e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0363e-01],\n",
      "          [ 1.9450e-01],\n",
      "          [ 1.1240e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5257e-02],\n",
      "          [ 7.1057e-02],\n",
      "          [ 2.6335e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0144e-02],\n",
      "          [-6.3022e-04],\n",
      "          [-7.2821e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5823e-01],\n",
      "          [-5.4094e-01],\n",
      "          [-5.6534e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7384e-01],\n",
      "          [-1.3358e-01],\n",
      "          [ 5.0244e-02]]]], device='cuda:0')}, 27: {'momentum_buffer': tensor([ 0.1698,  0.2016,  0.1481, -0.1691,  0.0674,  0.2909, -0.1118, -0.1719,\n",
      "         0.2448, -0.1429,  0.1574,  0.2148,  0.0018, -0.0259, -0.1449,  0.1441,\n",
      "        -0.0891, -0.5403,  0.0178,  0.2319, -0.3898,  0.0334,  0.2912, -0.3578],\n",
      "       device='cuda:0')}, 28: {'momentum_buffer': tensor([ 0.3597,  0.1445, -0.0339,  0.2205, -0.1519, -0.0896,  0.0151, -0.0306,\n",
      "         0.3509, -0.2393,  0.0709, -0.0892,  0.2427, -0.0578, -0.0754,  0.0655,\n",
      "        -0.0876, -0.1198,  0.3344, -0.7049,  0.2628,  0.0485,  0.3240,  0.5608],\n",
      "       device='cuda:0')}, 29: {'momentum_buffer': tensor([[[[-1.1932e-01,  2.0450e-01,  1.5559e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3994e-01, -2.8612e-03, -1.3051e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9219e-02, -9.0039e-03,  7.2075e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.0786e-02, -1.1417e-02,  2.5614e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4321e-02, -3.1949e-02, -6.6870e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7911e-05,  2.0834e-05, -6.4780e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7145e-01,  4.3053e-02, -1.3930e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0397e-01, -5.9355e-02, -1.3128e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3830e-01,  3.6284e-01,  2.1190e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8898e-02,  1.3929e-01,  1.2996e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9819e-02,  7.8093e-02,  8.3781e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5376e-03, -1.6892e-02, -7.9995e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.5577e-02,  1.1727e-01,  1.3232e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2005e-04,  2.2470e-02, -2.2726e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9923e-02,  8.1914e-02,  1.2063e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1008e-02, -1.0055e-01, -1.8618e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0200e-05, -8.6091e-06,  8.9026e-06]]],\n",
      "\n",
      "\n",
      "        [[[-8.5487e-02, -3.3136e-02,  3.5750e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5984e-02, -4.8060e-02,  1.2498e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1901e-02, -1.4258e-02,  3.4549e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.8277e-08, -4.8573e-10, -3.1138e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5993e-01,  1.1688e-01, -6.2648e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.5134e-02, -1.5069e-01, -1.9654e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2047e-07, -4.2066e-08, -7.7423e-08]]]], device='cuda:0')}, 30: {'momentum_buffer': tensor([ 4.3692e-01,  1.5823e-01, -9.2836e-02, -1.8833e-01,  2.7914e-01,\n",
      "        -1.2883e-06,  9.2179e-02,  3.2806e-02,  4.3111e-01, -3.7117e-01,\n",
      "         1.2983e-02,  1.7315e-01, -3.5040e-02,  1.4796e-01, -9.9384e-02,\n",
      "         6.1926e-02,  2.3285e-06, -5.7220e-01,  5.7916e-02, -1.4391e-01,\n",
      "         4.6458e-08,  9.3262e-03,  7.8684e-02,  1.5086e-08], device='cuda:0')}, 31: {'momentum_buffer': tensor([ 2.9121e-01,  1.6387e-01,  8.0933e-02, -1.3342e-01,  9.4812e-02,\n",
      "        -1.4428e-05,  4.4620e-02,  7.4542e-03,  2.2232e-01, -9.5595e-02,\n",
      "         3.8372e-02,  1.6150e-01,  6.8176e-02,  1.5656e-01,  5.6477e-02,\n",
      "        -1.7531e-01, -1.4051e-05, -3.7712e-01,  6.6037e-02, -5.2406e-02,\n",
      "        -5.8468e-08, -1.7839e-01,  2.8792e-02, -1.3458e-07], device='cuda:0')}, 32: {'momentum_buffer': tensor([[[[ 3.2153e-02]],\n",
      "\n",
      "         [[-3.7687e-02]],\n",
      "\n",
      "         [[ 2.7242e-01]],\n",
      "\n",
      "         [[ 3.1601e-01]],\n",
      "\n",
      "         [[ 2.6073e-01]],\n",
      "\n",
      "         [[-1.3274e-05]],\n",
      "\n",
      "         [[ 4.4653e-02]],\n",
      "\n",
      "         [[-6.8938e-04]],\n",
      "\n",
      "         [[ 1.2177e-01]],\n",
      "\n",
      "         [[-1.2551e-01]],\n",
      "\n",
      "         [[ 1.1817e-01]],\n",
      "\n",
      "         [[ 1.4245e-02]],\n",
      "\n",
      "         [[ 2.1428e-01]],\n",
      "\n",
      "         [[ 5.7144e-02]],\n",
      "\n",
      "         [[ 9.7022e-02]],\n",
      "\n",
      "         [[ 4.7776e-02]],\n",
      "\n",
      "         [[ 3.6765e-06]],\n",
      "\n",
      "         [[ 4.5153e-02]],\n",
      "\n",
      "         [[ 3.5825e-02]],\n",
      "\n",
      "         [[-1.9176e-02]],\n",
      "\n",
      "         [[-8.1346e-09]],\n",
      "\n",
      "         [[-3.7254e-03]],\n",
      "\n",
      "         [[ 5.4869e-02]],\n",
      "\n",
      "         [[ 2.8175e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8657e-01]],\n",
      "\n",
      "         [[ 1.2036e-02]],\n",
      "\n",
      "         [[-8.7293e-02]],\n",
      "\n",
      "         [[ 2.6421e-03]],\n",
      "\n",
      "         [[ 5.5004e-02]],\n",
      "\n",
      "         [[-4.3287e-05]],\n",
      "\n",
      "         [[ 1.4911e-01]],\n",
      "\n",
      "         [[ 1.9199e-03]],\n",
      "\n",
      "         [[ 6.0193e-02]],\n",
      "\n",
      "         [[ 3.3472e-01]],\n",
      "\n",
      "         [[-3.9364e-02]],\n",
      "\n",
      "         [[ 7.7310e-02]],\n",
      "\n",
      "         [[-4.1228e-02]],\n",
      "\n",
      "         [[ 1.3150e-02]],\n",
      "\n",
      "         [[-7.3090e-02]],\n",
      "\n",
      "         [[-1.2080e-02]],\n",
      "\n",
      "         [[-1.0268e-05]],\n",
      "\n",
      "         [[ 9.6405e-03]],\n",
      "\n",
      "         [[ 5.2587e-02]],\n",
      "\n",
      "         [[ 1.7323e-02]],\n",
      "\n",
      "         [[ 2.2927e-09]],\n",
      "\n",
      "         [[ 2.7356e-02]],\n",
      "\n",
      "         [[-4.4730e-02]],\n",
      "\n",
      "         [[ 1.4155e-08]]],\n",
      "\n",
      "\n",
      "        [[[-3.1217e-02]],\n",
      "\n",
      "         [[-3.8544e-04]],\n",
      "\n",
      "         [[-5.0361e-03]],\n",
      "\n",
      "         [[-1.3456e-03]],\n",
      "\n",
      "         [[ 4.3832e-03]],\n",
      "\n",
      "         [[-7.7209e-05]],\n",
      "\n",
      "         [[ 1.3680e-03]],\n",
      "\n",
      "         [[ 2.8151e-02]],\n",
      "\n",
      "         [[-3.8998e-04]],\n",
      "\n",
      "         [[ 8.4401e-03]],\n",
      "\n",
      "         [[ 7.2841e-03]],\n",
      "\n",
      "         [[-1.6185e-02]],\n",
      "\n",
      "         [[-2.6127e-02]],\n",
      "\n",
      "         [[-2.0292e-02]],\n",
      "\n",
      "         [[-3.0203e-03]],\n",
      "\n",
      "         [[-1.1672e-02]],\n",
      "\n",
      "         [[-2.6703e-06]],\n",
      "\n",
      "         [[ 2.8982e-03]],\n",
      "\n",
      "         [[-1.6420e-02]],\n",
      "\n",
      "         [[-3.1173e-02]],\n",
      "\n",
      "         [[ 2.9830e-10]],\n",
      "\n",
      "         [[ 2.6132e-03]],\n",
      "\n",
      "         [[-3.6865e-02]],\n",
      "\n",
      "         [[-1.4324e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7393e-02]],\n",
      "\n",
      "         [[-1.1317e-03]],\n",
      "\n",
      "         [[-5.5784e-02]],\n",
      "\n",
      "         [[-4.7445e-03]],\n",
      "\n",
      "         [[-6.9782e-03]],\n",
      "\n",
      "         [[ 2.1082e-05]],\n",
      "\n",
      "         [[ 1.2242e-02]],\n",
      "\n",
      "         [[-2.2714e-02]],\n",
      "\n",
      "         [[-4.0845e-02]],\n",
      "\n",
      "         [[-1.5636e-02]],\n",
      "\n",
      "         [[-5.0967e-04]],\n",
      "\n",
      "         [[ 8.7472e-02]],\n",
      "\n",
      "         [[-2.5920e-02]],\n",
      "\n",
      "         [[-2.3806e-02]],\n",
      "\n",
      "         [[ 1.0097e-02]],\n",
      "\n",
      "         [[ 5.4018e-02]],\n",
      "\n",
      "         [[ 9.5027e-06]],\n",
      "\n",
      "         [[-1.3903e-01]],\n",
      "\n",
      "         [[ 2.6949e-02]],\n",
      "\n",
      "         [[-2.5911e-02]],\n",
      "\n",
      "         [[ 2.4411e-08]],\n",
      "\n",
      "         [[ 2.8531e-02]],\n",
      "\n",
      "         [[-1.5962e-02]],\n",
      "\n",
      "         [[-4.5988e-09]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1552e-02]],\n",
      "\n",
      "         [[ 4.0477e-03]],\n",
      "\n",
      "         [[ 5.1743e-04]],\n",
      "\n",
      "         [[ 1.1715e-03]],\n",
      "\n",
      "         [[-3.1514e-03]],\n",
      "\n",
      "         [[-2.4206e-05]],\n",
      "\n",
      "         [[ 1.2313e-01]],\n",
      "\n",
      "         [[ 6.2609e-03]],\n",
      "\n",
      "         [[ 2.3825e-02]],\n",
      "\n",
      "         [[ 4.0822e-02]],\n",
      "\n",
      "         [[ 1.1748e-02]],\n",
      "\n",
      "         [[ 2.5859e-02]],\n",
      "\n",
      "         [[-5.6901e-02]],\n",
      "\n",
      "         [[-9.3206e-03]],\n",
      "\n",
      "         [[ 2.3327e-02]],\n",
      "\n",
      "         [[-2.7694e-02]],\n",
      "\n",
      "         [[ 3.3186e-06]],\n",
      "\n",
      "         [[ 1.5127e-02]],\n",
      "\n",
      "         [[ 3.7866e-02]],\n",
      "\n",
      "         [[-2.7152e-02]],\n",
      "\n",
      "         [[-8.8480e-09]],\n",
      "\n",
      "         [[-1.9937e-02]],\n",
      "\n",
      "         [[-2.0855e-02]],\n",
      "\n",
      "         [[-4.3403e-08]]],\n",
      "\n",
      "\n",
      "        [[[-4.2875e-02]],\n",
      "\n",
      "         [[-2.7319e-02]],\n",
      "\n",
      "         [[-1.7957e-02]],\n",
      "\n",
      "         [[ 1.1424e-03]],\n",
      "\n",
      "         [[ 3.6238e-02]],\n",
      "\n",
      "         [[-2.8077e-05]],\n",
      "\n",
      "         [[-1.8397e-01]],\n",
      "\n",
      "         [[-3.7064e-02]],\n",
      "\n",
      "         [[-5.1137e-02]],\n",
      "\n",
      "         [[-1.8579e-02]],\n",
      "\n",
      "         [[ 1.6785e-02]],\n",
      "\n",
      "         [[ 2.5024e-02]],\n",
      "\n",
      "         [[-1.3075e-02]],\n",
      "\n",
      "         [[ 4.0247e-02]],\n",
      "\n",
      "         [[ 2.1361e-03]],\n",
      "\n",
      "         [[ 1.2543e-02]],\n",
      "\n",
      "         [[ 2.0625e-06]],\n",
      "\n",
      "         [[-2.3394e-02]],\n",
      "\n",
      "         [[-2.0203e-02]],\n",
      "\n",
      "         [[-1.4080e-02]],\n",
      "\n",
      "         [[-1.1547e-08]],\n",
      "\n",
      "         [[ 3.1348e-02]],\n",
      "\n",
      "         [[-1.9937e-02]],\n",
      "\n",
      "         [[ 3.4877e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.2864e-01]],\n",
      "\n",
      "         [[ 4.0935e-03]],\n",
      "\n",
      "         [[-3.0881e-01]],\n",
      "\n",
      "         [[-2.1400e-01]],\n",
      "\n",
      "         [[-9.8757e-02]],\n",
      "\n",
      "         [[ 1.0831e-05]],\n",
      "\n",
      "         [[-5.4410e-03]],\n",
      "\n",
      "         [[-2.3724e-02]],\n",
      "\n",
      "         [[-1.7749e-01]],\n",
      "\n",
      "         [[-1.1484e-01]],\n",
      "\n",
      "         [[-1.4461e-01]],\n",
      "\n",
      "         [[-9.1158e-02]],\n",
      "\n",
      "         [[-6.6213e-01]],\n",
      "\n",
      "         [[-9.4902e-02]],\n",
      "\n",
      "         [[-9.9973e-02]],\n",
      "\n",
      "         [[-3.5667e-01]],\n",
      "\n",
      "         [[-8.9873e-06]],\n",
      "\n",
      "         [[ 3.9762e-02]],\n",
      "\n",
      "         [[-6.9892e-02]],\n",
      "\n",
      "         [[-1.1715e-01]],\n",
      "\n",
      "         [[ 2.0966e-08]],\n",
      "\n",
      "         [[-1.4965e-01]],\n",
      "\n",
      "         [[-3.3184e-01]],\n",
      "\n",
      "         [[-1.4002e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.1119e-02]],\n",
      "\n",
      "         [[ 4.7628e-02]],\n",
      "\n",
      "         [[-1.3704e-01]],\n",
      "\n",
      "         [[ 5.3947e-02]],\n",
      "\n",
      "         [[ 4.5791e-02]],\n",
      "\n",
      "         [[-9.1479e-06]],\n",
      "\n",
      "         [[-4.4879e-03]],\n",
      "\n",
      "         [[-2.9220e-04]],\n",
      "\n",
      "         [[-2.6090e-02]],\n",
      "\n",
      "         [[-1.0885e-01]],\n",
      "\n",
      "         [[-8.5112e-02]],\n",
      "\n",
      "         [[-3.1526e-02]],\n",
      "\n",
      "         [[-1.0847e-01]],\n",
      "\n",
      "         [[-4.3952e-02]],\n",
      "\n",
      "         [[-1.5095e-02]],\n",
      "\n",
      "         [[ 5.3853e-03]],\n",
      "\n",
      "         [[-1.3467e-05]],\n",
      "\n",
      "         [[ 5.3496e-02]],\n",
      "\n",
      "         [[-1.0637e-02]],\n",
      "\n",
      "         [[-1.7800e-03]],\n",
      "\n",
      "         [[-3.1553e-09]],\n",
      "\n",
      "         [[-1.4195e-02]],\n",
      "\n",
      "         [[ 3.4574e-02]],\n",
      "\n",
      "         [[-1.1159e-08]]],\n",
      "\n",
      "\n",
      "        [[[-3.1546e-02]],\n",
      "\n",
      "         [[ 4.2059e-04]],\n",
      "\n",
      "         [[ 6.9826e-02]],\n",
      "\n",
      "         [[ 3.8981e-04]],\n",
      "\n",
      "         [[ 9.8180e-02]],\n",
      "\n",
      "         [[-3.1439e-05]],\n",
      "\n",
      "         [[-3.5191e-01]],\n",
      "\n",
      "         [[-1.8761e-02]],\n",
      "\n",
      "         [[-5.6484e-02]],\n",
      "\n",
      "         [[-6.2063e-02]],\n",
      "\n",
      "         [[ 8.2927e-02]],\n",
      "\n",
      "         [[ 8.4003e-02]],\n",
      "\n",
      "         [[ 6.0818e-02]],\n",
      "\n",
      "         [[ 8.7757e-02]],\n",
      "\n",
      "         [[ 1.8137e-03]],\n",
      "\n",
      "         [[ 8.8706e-02]],\n",
      "\n",
      "         [[-8.2362e-06]],\n",
      "\n",
      "         [[ 3.9222e-02]],\n",
      "\n",
      "         [[ 2.0421e-02]],\n",
      "\n",
      "         [[ 9.6779e-02]],\n",
      "\n",
      "         [[-1.6287e-08]],\n",
      "\n",
      "         [[ 2.6752e-01]],\n",
      "\n",
      "         [[ 1.0411e-01]],\n",
      "\n",
      "         [[ 5.7685e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.0060e-02]],\n",
      "\n",
      "         [[-2.2140e-03]],\n",
      "\n",
      "         [[-3.8436e-03]],\n",
      "\n",
      "         [[-1.6663e-02]],\n",
      "\n",
      "         [[-9.5096e-02]],\n",
      "\n",
      "         [[ 4.6862e-07]],\n",
      "\n",
      "         [[-3.0960e-04]],\n",
      "\n",
      "         [[-1.6101e-03]],\n",
      "\n",
      "         [[-1.6729e-02]],\n",
      "\n",
      "         [[-2.5470e-02]],\n",
      "\n",
      "         [[ 4.2701e-02]],\n",
      "\n",
      "         [[ 5.2626e-03]],\n",
      "\n",
      "         [[ 1.1391e-01]],\n",
      "\n",
      "         [[-2.6348e-02]],\n",
      "\n",
      "         [[ 6.2584e-03]],\n",
      "\n",
      "         [[-6.9353e-02]],\n",
      "\n",
      "         [[-7.4898e-06]],\n",
      "\n",
      "         [[-7.7105e-02]],\n",
      "\n",
      "         [[-3.3865e-03]],\n",
      "\n",
      "         [[-1.9687e-02]],\n",
      "\n",
      "         [[-1.6874e-08]],\n",
      "\n",
      "         [[-1.9716e-02]],\n",
      "\n",
      "         [[-4.1062e-02]],\n",
      "\n",
      "         [[-4.0254e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.2739e-02]],\n",
      "\n",
      "         [[ 1.8762e-02]],\n",
      "\n",
      "         [[ 2.5883e-02]],\n",
      "\n",
      "         [[-4.0546e-02]],\n",
      "\n",
      "         [[ 1.8268e-02]],\n",
      "\n",
      "         [[-2.2866e-05]],\n",
      "\n",
      "         [[ 2.2705e-02]],\n",
      "\n",
      "         [[-6.0195e-03]],\n",
      "\n",
      "         [[-1.2111e-01]],\n",
      "\n",
      "         [[ 6.5527e-02]],\n",
      "\n",
      "         [[ 2.2772e-02]],\n",
      "\n",
      "         [[-4.5928e-02]],\n",
      "\n",
      "         [[ 5.7207e-02]],\n",
      "\n",
      "         [[ 4.1113e-02]],\n",
      "\n",
      "         [[-3.7920e-02]],\n",
      "\n",
      "         [[ 2.1237e-02]],\n",
      "\n",
      "         [[-5.9152e-06]],\n",
      "\n",
      "         [[ 6.8141e-02]],\n",
      "\n",
      "         [[ 1.1997e-02]],\n",
      "\n",
      "         [[ 6.1050e-02]],\n",
      "\n",
      "         [[ 1.4793e-09]],\n",
      "\n",
      "         [[ 5.7421e-02]],\n",
      "\n",
      "         [[ 6.7616e-02]],\n",
      "\n",
      "         [[-1.3345e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4253e-01]],\n",
      "\n",
      "         [[ 3.3727e-02]],\n",
      "\n",
      "         [[ 8.3806e-02]],\n",
      "\n",
      "         [[ 1.9915e-02]],\n",
      "\n",
      "         [[ 2.6072e-02]],\n",
      "\n",
      "         [[-2.6240e-06]],\n",
      "\n",
      "         [[ 1.1732e-01]],\n",
      "\n",
      "         [[ 2.3479e-02]],\n",
      "\n",
      "         [[ 8.3499e-02]],\n",
      "\n",
      "         [[ 3.2254e-02]],\n",
      "\n",
      "         [[-2.8343e-02]],\n",
      "\n",
      "         [[ 4.3485e-02]],\n",
      "\n",
      "         [[-6.5702e-02]],\n",
      "\n",
      "         [[ 5.1194e-02]],\n",
      "\n",
      "         [[ 2.7189e-02]],\n",
      "\n",
      "         [[-4.5095e-02]],\n",
      "\n",
      "         [[-1.0428e-05]],\n",
      "\n",
      "         [[ 1.4398e-01]],\n",
      "\n",
      "         [[ 1.3334e-02]],\n",
      "\n",
      "         [[ 4.9744e-02]],\n",
      "\n",
      "         [[-1.3431e-08]],\n",
      "\n",
      "         [[ 1.0395e-01]],\n",
      "\n",
      "         [[-4.9616e-02]],\n",
      "\n",
      "         [[-1.4911e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1235e-02]],\n",
      "\n",
      "         [[ 2.7365e-02]],\n",
      "\n",
      "         [[ 2.0912e-01]],\n",
      "\n",
      "         [[ 2.8338e-02]],\n",
      "\n",
      "         [[ 1.9826e-01]],\n",
      "\n",
      "         [[-1.5144e-05]],\n",
      "\n",
      "         [[-1.8140e-02]],\n",
      "\n",
      "         [[-6.0400e-02]],\n",
      "\n",
      "         [[-2.4117e-03]],\n",
      "\n",
      "         [[ 6.0096e-02]],\n",
      "\n",
      "         [[-6.8120e-02]],\n",
      "\n",
      "         [[ 4.2516e-02]],\n",
      "\n",
      "         [[ 7.9264e-03]],\n",
      "\n",
      "         [[-5.3736e-02]],\n",
      "\n",
      "         [[ 7.5086e-02]],\n",
      "\n",
      "         [[ 1.2763e-01]],\n",
      "\n",
      "         [[ 3.2159e-06]],\n",
      "\n",
      "         [[ 6.6508e-02]],\n",
      "\n",
      "         [[ 1.5371e-02]],\n",
      "\n",
      "         [[-4.9223e-02]],\n",
      "\n",
      "         [[ 1.1601e-08]],\n",
      "\n",
      "         [[-3.7673e-01]],\n",
      "\n",
      "         [[-4.0209e-02]],\n",
      "\n",
      "         [[-1.8331e-08]]],\n",
      "\n",
      "\n",
      "        [[[-9.8882e-04]],\n",
      "\n",
      "         [[-1.7741e-03]],\n",
      "\n",
      "         [[ 4.6658e-03]],\n",
      "\n",
      "         [[ 1.5024e-02]],\n",
      "\n",
      "         [[ 8.2587e-02]],\n",
      "\n",
      "         [[-2.9820e-05]],\n",
      "\n",
      "         [[ 7.2549e-02]],\n",
      "\n",
      "         [[-5.1558e-04]],\n",
      "\n",
      "         [[ 7.6780e-03]],\n",
      "\n",
      "         [[ 9.2881e-02]],\n",
      "\n",
      "         [[-2.3164e-02]],\n",
      "\n",
      "         [[ 2.5101e-02]],\n",
      "\n",
      "         [[ 2.2542e-02]],\n",
      "\n",
      "         [[ 3.8911e-02]],\n",
      "\n",
      "         [[-2.8705e-02]],\n",
      "\n",
      "         [[ 2.9805e-02]],\n",
      "\n",
      "         [[-3.3386e-06]],\n",
      "\n",
      "         [[ 9.3254e-02]],\n",
      "\n",
      "         [[-2.1613e-02]],\n",
      "\n",
      "         [[ 2.4217e-02]],\n",
      "\n",
      "         [[-2.5007e-08]],\n",
      "\n",
      "         [[-1.2123e-02]],\n",
      "\n",
      "         [[-4.0648e-02]],\n",
      "\n",
      "         [[-4.7088e-08]]],\n",
      "\n",
      "\n",
      "        [[[-3.6180e-02]],\n",
      "\n",
      "         [[ 5.6333e-02]],\n",
      "\n",
      "         [[ 4.2634e-02]],\n",
      "\n",
      "         [[-3.8664e-02]],\n",
      "\n",
      "         [[-2.1087e-02]],\n",
      "\n",
      "         [[-2.5533e-05]],\n",
      "\n",
      "         [[-5.5153e-02]],\n",
      "\n",
      "         [[ 5.9426e-03]],\n",
      "\n",
      "         [[-8.4611e-03]],\n",
      "\n",
      "         [[ 1.9473e-02]],\n",
      "\n",
      "         [[-1.0739e-02]],\n",
      "\n",
      "         [[-3.1216e-02]],\n",
      "\n",
      "         [[ 2.0768e-02]],\n",
      "\n",
      "         [[ 5.6187e-02]],\n",
      "\n",
      "         [[ 2.7927e-02]],\n",
      "\n",
      "         [[ 1.6783e-02]],\n",
      "\n",
      "         [[-8.5401e-07]],\n",
      "\n",
      "         [[ 1.0484e-01]],\n",
      "\n",
      "         [[-5.4682e-02]],\n",
      "\n",
      "         [[ 2.8647e-02]],\n",
      "\n",
      "         [[-3.2118e-08]],\n",
      "\n",
      "         [[-7.8540e-02]],\n",
      "\n",
      "         [[ 3.6185e-02]],\n",
      "\n",
      "         [[-1.5253e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.4732e-02]],\n",
      "\n",
      "         [[-2.5798e-02]],\n",
      "\n",
      "         [[ 3.7776e-02]],\n",
      "\n",
      "         [[ 3.2300e-02]],\n",
      "\n",
      "         [[ 8.3733e-02]],\n",
      "\n",
      "         [[-1.2645e-05]],\n",
      "\n",
      "         [[ 1.0444e-01]],\n",
      "\n",
      "         [[ 2.8145e-02]],\n",
      "\n",
      "         [[ 1.6342e-02]],\n",
      "\n",
      "         [[ 3.9220e-02]],\n",
      "\n",
      "         [[-2.8320e-03]],\n",
      "\n",
      "         [[-1.8985e-02]],\n",
      "\n",
      "         [[ 4.6790e-02]],\n",
      "\n",
      "         [[-3.8877e-02]],\n",
      "\n",
      "         [[-2.5012e-02]],\n",
      "\n",
      "         [[ 4.4045e-02]],\n",
      "\n",
      "         [[-4.7019e-06]],\n",
      "\n",
      "         [[ 1.3872e-02]],\n",
      "\n",
      "         [[-5.2449e-03]],\n",
      "\n",
      "         [[ 3.6984e-02]],\n",
      "\n",
      "         [[-1.7431e-08]],\n",
      "\n",
      "         [[ 4.5318e-02]],\n",
      "\n",
      "         [[-3.0496e-02]],\n",
      "\n",
      "         [[ 1.0802e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.4182e-02]],\n",
      "\n",
      "         [[-1.5356e-02]],\n",
      "\n",
      "         [[ 1.3137e-01]],\n",
      "\n",
      "         [[-3.1976e-02]],\n",
      "\n",
      "         [[-1.9439e-01]],\n",
      "\n",
      "         [[-3.4261e-06]],\n",
      "\n",
      "         [[-3.7437e-02]],\n",
      "\n",
      "         [[-4.8233e-02]],\n",
      "\n",
      "         [[ 1.6887e-01]],\n",
      "\n",
      "         [[-1.0217e-01]],\n",
      "\n",
      "         [[ 1.3102e-01]],\n",
      "\n",
      "         [[ 9.2906e-02]],\n",
      "\n",
      "         [[-2.3891e-02]],\n",
      "\n",
      "         [[-1.3448e-01]],\n",
      "\n",
      "         [[ 7.8409e-02]],\n",
      "\n",
      "         [[ 5.7495e-03]],\n",
      "\n",
      "         [[-1.2743e-06]],\n",
      "\n",
      "         [[-7.6590e-02]],\n",
      "\n",
      "         [[ 3.7466e-02]],\n",
      "\n",
      "         [[-1.1708e-01]],\n",
      "\n",
      "         [[-2.2714e-08]],\n",
      "\n",
      "         [[-2.6558e-01]],\n",
      "\n",
      "         [[-1.0086e-01]],\n",
      "\n",
      "         [[-1.0925e-08]]],\n",
      "\n",
      "\n",
      "        [[[-7.4447e-02]],\n",
      "\n",
      "         [[-8.3891e-02]],\n",
      "\n",
      "         [[-1.4961e-01]],\n",
      "\n",
      "         [[-4.0832e-02]],\n",
      "\n",
      "         [[-7.1018e-02]],\n",
      "\n",
      "         [[ 1.4186e-05]],\n",
      "\n",
      "         [[-3.7979e-02]],\n",
      "\n",
      "         [[-1.1219e-02]],\n",
      "\n",
      "         [[-8.3698e-02]],\n",
      "\n",
      "         [[ 3.2948e-02]],\n",
      "\n",
      "         [[-3.8057e-02]],\n",
      "\n",
      "         [[-2.1068e-02]],\n",
      "\n",
      "         [[-4.4621e-02]],\n",
      "\n",
      "         [[ 1.0133e-01]],\n",
      "\n",
      "         [[ 2.9394e-02]],\n",
      "\n",
      "         [[-3.3590e-02]],\n",
      "\n",
      "         [[-6.9795e-07]],\n",
      "\n",
      "         [[-1.5135e-01]],\n",
      "\n",
      "         [[ 2.9207e-02]],\n",
      "\n",
      "         [[ 1.0589e-02]],\n",
      "\n",
      "         [[ 3.7796e-09]],\n",
      "\n",
      "         [[-4.1584e-02]],\n",
      "\n",
      "         [[-3.3770e-02]],\n",
      "\n",
      "         [[-4.3716e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2846e-02]],\n",
      "\n",
      "         [[ 4.4678e-02]],\n",
      "\n",
      "         [[ 7.0585e-02]],\n",
      "\n",
      "         [[ 1.2202e-01]],\n",
      "\n",
      "         [[ 3.2821e-01]],\n",
      "\n",
      "         [[ 6.3165e-06]],\n",
      "\n",
      "         [[ 4.0155e-02]],\n",
      "\n",
      "         [[ 1.2547e-02]],\n",
      "\n",
      "         [[ 1.0497e-02]],\n",
      "\n",
      "         [[ 3.1725e-02]],\n",
      "\n",
      "         [[-1.8335e-02]],\n",
      "\n",
      "         [[ 3.3179e-02]],\n",
      "\n",
      "         [[ 6.1218e-02]],\n",
      "\n",
      "         [[ 3.8434e-02]],\n",
      "\n",
      "         [[ 2.6082e-02]],\n",
      "\n",
      "         [[ 7.3748e-02]],\n",
      "\n",
      "         [[-5.6444e-06]],\n",
      "\n",
      "         [[ 1.0362e-01]],\n",
      "\n",
      "         [[-2.1222e-03]],\n",
      "\n",
      "         [[-2.0996e-02]],\n",
      "\n",
      "         [[ 1.2776e-08]],\n",
      "\n",
      "         [[-1.0410e-01]],\n",
      "\n",
      "         [[ 6.8480e-02]],\n",
      "\n",
      "         [[-6.5662e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.2624e-01]],\n",
      "\n",
      "         [[-2.4402e-01]],\n",
      "\n",
      "         [[-4.1609e-01]],\n",
      "\n",
      "         [[-2.6764e-01]],\n",
      "\n",
      "         [[-1.2640e-01]],\n",
      "\n",
      "         [[ 4.4158e-05]],\n",
      "\n",
      "         [[-3.2654e-01]],\n",
      "\n",
      "         [[ 8.3056e-03]],\n",
      "\n",
      "         [[-1.6824e-01]],\n",
      "\n",
      "         [[-1.6299e-01]],\n",
      "\n",
      "         [[ 3.5889e-02]],\n",
      "\n",
      "         [[ 1.1695e-01]],\n",
      "\n",
      "         [[-1.9563e-01]],\n",
      "\n",
      "         [[-7.1100e-02]],\n",
      "\n",
      "         [[-1.0751e-01]],\n",
      "\n",
      "         [[ 1.8364e-02]],\n",
      "\n",
      "         [[ 2.2181e-06]],\n",
      "\n",
      "         [[-6.2967e-01]],\n",
      "\n",
      "         [[ 3.8145e-03]],\n",
      "\n",
      "         [[-2.9534e-03]],\n",
      "\n",
      "         [[-3.8305e-08]],\n",
      "\n",
      "         [[ 1.3795e-01]],\n",
      "\n",
      "         [[-2.6094e-02]],\n",
      "\n",
      "         [[-8.0864e-10]]],\n",
      "\n",
      "\n",
      "        [[[-1.4325e-02]],\n",
      "\n",
      "         [[-2.4663e-02]],\n",
      "\n",
      "         [[ 3.8407e-02]],\n",
      "\n",
      "         [[ 1.5095e-02]],\n",
      "\n",
      "         [[-2.0552e-02]],\n",
      "\n",
      "         [[-3.4100e-05]],\n",
      "\n",
      "         [[ 3.3361e-01]],\n",
      "\n",
      "         [[ 3.0734e-03]],\n",
      "\n",
      "         [[ 5.3769e-02]],\n",
      "\n",
      "         [[ 1.1473e-01]],\n",
      "\n",
      "         [[-1.5175e-02]],\n",
      "\n",
      "         [[ 1.1891e-02]],\n",
      "\n",
      "         [[ 1.4785e-01]],\n",
      "\n",
      "         [[-2.2844e-02]],\n",
      "\n",
      "         [[-1.0028e-02]],\n",
      "\n",
      "         [[ 4.3812e-02]],\n",
      "\n",
      "         [[-4.5333e-06]],\n",
      "\n",
      "         [[ 8.6940e-02]],\n",
      "\n",
      "         [[-4.3593e-02]],\n",
      "\n",
      "         [[-6.9099e-02]],\n",
      "\n",
      "         [[ 7.5319e-09]],\n",
      "\n",
      "         [[ 3.9019e-02]],\n",
      "\n",
      "         [[-1.9617e-02]],\n",
      "\n",
      "         [[-5.7080e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.3457e-02]],\n",
      "\n",
      "         [[-2.3882e-02]],\n",
      "\n",
      "         [[ 5.9161e-02]],\n",
      "\n",
      "         [[ 1.4733e-02]],\n",
      "\n",
      "         [[ 6.9944e-03]],\n",
      "\n",
      "         [[-2.0127e-05]],\n",
      "\n",
      "         [[-5.5409e-04]],\n",
      "\n",
      "         [[-1.4085e-04]],\n",
      "\n",
      "         [[ 9.3782e-03]],\n",
      "\n",
      "         [[ 3.7707e-04]],\n",
      "\n",
      "         [[ 4.1832e-02]],\n",
      "\n",
      "         [[-6.7433e-03]],\n",
      "\n",
      "         [[ 1.5292e-02]],\n",
      "\n",
      "         [[ 4.4841e-05]],\n",
      "\n",
      "         [[ 2.5841e-02]],\n",
      "\n",
      "         [[ 4.2981e-02]],\n",
      "\n",
      "         [[ 1.1866e-05]],\n",
      "\n",
      "         [[-2.5560e-03]],\n",
      "\n",
      "         [[ 2.0770e-02]],\n",
      "\n",
      "         [[-2.8746e-03]],\n",
      "\n",
      "         [[-5.9206e-09]],\n",
      "\n",
      "         [[ 8.6096e-03]],\n",
      "\n",
      "         [[ 2.3260e-02]],\n",
      "\n",
      "         [[-1.4866e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.5545e-02]],\n",
      "\n",
      "         [[ 5.3406e-02]],\n",
      "\n",
      "         [[-3.9706e-02]],\n",
      "\n",
      "         [[-1.4997e-01]],\n",
      "\n",
      "         [[-6.6369e-02]],\n",
      "\n",
      "         [[-2.0336e-05]],\n",
      "\n",
      "         [[ 4.9084e-01]],\n",
      "\n",
      "         [[ 1.6038e-01]],\n",
      "\n",
      "         [[-1.5814e-01]],\n",
      "\n",
      "         [[ 2.3801e-03]],\n",
      "\n",
      "         [[-8.6894e-02]],\n",
      "\n",
      "         [[-2.8447e-02]],\n",
      "\n",
      "         [[ 1.4394e-01]],\n",
      "\n",
      "         [[ 1.9492e-02]],\n",
      "\n",
      "         [[-1.8334e-01]],\n",
      "\n",
      "         [[ 9.6723e-03]],\n",
      "\n",
      "         [[-4.1097e-06]],\n",
      "\n",
      "         [[ 4.6895e-02]],\n",
      "\n",
      "         [[-9.7689e-02]],\n",
      "\n",
      "         [[ 1.0335e-02]],\n",
      "\n",
      "         [[-1.9440e-08]],\n",
      "\n",
      "         [[ 1.5487e-01]],\n",
      "\n",
      "         [[ 2.3088e-02]],\n",
      "\n",
      "         [[-4.0258e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1948e-01]],\n",
      "\n",
      "         [[ 2.9501e-02]],\n",
      "\n",
      "         [[ 3.9509e-03]],\n",
      "\n",
      "         [[ 4.7816e-02]],\n",
      "\n",
      "         [[ 1.1193e-01]],\n",
      "\n",
      "         [[-3.9210e-06]],\n",
      "\n",
      "         [[ 6.4833e-02]],\n",
      "\n",
      "         [[-4.6317e-02]],\n",
      "\n",
      "         [[ 1.0769e-01]],\n",
      "\n",
      "         [[ 3.5097e-02]],\n",
      "\n",
      "         [[-2.0137e-02]],\n",
      "\n",
      "         [[ 5.6468e-02]],\n",
      "\n",
      "         [[-1.5123e-02]],\n",
      "\n",
      "         [[ 3.5310e-02]],\n",
      "\n",
      "         [[ 3.6033e-02]],\n",
      "\n",
      "         [[ 5.9023e-02]],\n",
      "\n",
      "         [[ 1.0818e-06]],\n",
      "\n",
      "         [[ 9.6078e-03]],\n",
      "\n",
      "         [[ 3.3789e-02]],\n",
      "\n",
      "         [[-2.5432e-02]],\n",
      "\n",
      "         [[ 2.7197e-08]],\n",
      "\n",
      "         [[-4.8920e-02]],\n",
      "\n",
      "         [[-3.6621e-03]],\n",
      "\n",
      "         [[ 5.8728e-09]]]], device='cuda:0')}, 33: {'momentum_buffer': tensor([-0.0254, -0.0064, -0.0158, -0.0231,  0.0060,  0.0371, -0.0201, -0.0408,\n",
      "         0.0041,  0.0229, -0.0263, -0.0060,  0.0102, -0.0081, -0.0040,  0.0138,\n",
      "         0.1340, -0.0457,  0.0376,  0.0076,  0.0169,  0.0252,  0.0096,  0.0537],\n",
      "       device='cuda:0')}, 34: {'momentum_buffer': tensor([ 0.0582,  0.0552, -0.0334, -0.0152, -0.0263, -0.1084, -0.0604, -0.0848,\n",
      "        -0.0988,  0.0186, -0.0138, -0.0207,  0.0564,  0.0316,  0.0275,  0.0592,\n",
      "         0.2674, -0.0266,  0.0242, -0.1133,  0.0212,  0.1413, -0.2336,  0.0042],\n",
      "       device='cuda:0')}, 35: {'momentum_buffer': tensor([[[[ 1.3072e-01]],\n",
      "\n",
      "         [[ 4.6276e-02]],\n",
      "\n",
      "         [[ 3.3198e-02]],\n",
      "\n",
      "         [[-1.6721e-02]],\n",
      "\n",
      "         [[ 2.4272e-02]],\n",
      "\n",
      "         [[-2.0271e-03]],\n",
      "\n",
      "         [[-4.7001e-02]],\n",
      "\n",
      "         [[-3.1890e-02]],\n",
      "\n",
      "         [[ 1.7480e-02]],\n",
      "\n",
      "         [[ 2.8772e-02]],\n",
      "\n",
      "         [[-3.3281e-02]],\n",
      "\n",
      "         [[-6.3961e-02]],\n",
      "\n",
      "         [[ 5.5407e-03]],\n",
      "\n",
      "         [[-7.8861e-03]],\n",
      "\n",
      "         [[ 1.9257e-02]],\n",
      "\n",
      "         [[ 1.8898e-02]],\n",
      "\n",
      "         [[ 4.6937e-02]],\n",
      "\n",
      "         [[ 6.7293e-02]],\n",
      "\n",
      "         [[ 6.6053e-02]],\n",
      "\n",
      "         [[ 3.9089e-03]],\n",
      "\n",
      "         [[-1.1446e-02]],\n",
      "\n",
      "         [[ 4.9149e-03]],\n",
      "\n",
      "         [[ 1.4882e-02]],\n",
      "\n",
      "         [[ 6.3511e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7793e-03]],\n",
      "\n",
      "         [[ 5.9960e-03]],\n",
      "\n",
      "         [[ 6.5876e-04]],\n",
      "\n",
      "         [[ 1.3227e-02]],\n",
      "\n",
      "         [[-1.6635e-03]],\n",
      "\n",
      "         [[ 3.5600e-04]],\n",
      "\n",
      "         [[-5.5190e-04]],\n",
      "\n",
      "         [[-9.5330e-03]],\n",
      "\n",
      "         [[ 2.4352e-03]],\n",
      "\n",
      "         [[ 2.8356e-02]],\n",
      "\n",
      "         [[-2.5477e-03]],\n",
      "\n",
      "         [[ 2.5867e-02]],\n",
      "\n",
      "         [[-1.1547e-03]],\n",
      "\n",
      "         [[-1.6327e-03]],\n",
      "\n",
      "         [[ 5.1468e-03]],\n",
      "\n",
      "         [[ 3.3086e-03]],\n",
      "\n",
      "         [[ 4.5616e-03]],\n",
      "\n",
      "         [[ 1.5905e-02]],\n",
      "\n",
      "         [[ 2.2783e-02]],\n",
      "\n",
      "         [[ 4.5950e-03]],\n",
      "\n",
      "         [[ 1.4501e-03]],\n",
      "\n",
      "         [[-8.5000e-04]],\n",
      "\n",
      "         [[-3.8597e-03]],\n",
      "\n",
      "         [[ 6.4964e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0815e-02]],\n",
      "\n",
      "         [[ 9.1673e-03]],\n",
      "\n",
      "         [[ 6.8298e-03]],\n",
      "\n",
      "         [[ 1.6415e-02]],\n",
      "\n",
      "         [[-3.1752e-03]],\n",
      "\n",
      "         [[-6.1573e-03]],\n",
      "\n",
      "         [[-2.4862e-03]],\n",
      "\n",
      "         [[ 1.5017e-03]],\n",
      "\n",
      "         [[ 8.4270e-04]],\n",
      "\n",
      "         [[-1.0138e-03]],\n",
      "\n",
      "         [[-5.9373e-04]],\n",
      "\n",
      "         [[ 1.5753e-02]],\n",
      "\n",
      "         [[ 3.5913e-03]],\n",
      "\n",
      "         [[-8.4403e-03]],\n",
      "\n",
      "         [[ 8.8314e-04]],\n",
      "\n",
      "         [[ 1.0776e-02]],\n",
      "\n",
      "         [[ 1.4537e-02]],\n",
      "\n",
      "         [[ 2.0991e-02]],\n",
      "\n",
      "         [[ 3.2112e-03]],\n",
      "\n",
      "         [[ 7.1921e-03]],\n",
      "\n",
      "         [[ 5.5332e-03]],\n",
      "\n",
      "         [[ 6.3095e-03]],\n",
      "\n",
      "         [[ 2.0272e-02]],\n",
      "\n",
      "         [[ 6.9254e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3038e-02]],\n",
      "\n",
      "         [[-6.4609e-02]],\n",
      "\n",
      "         [[-4.0493e-02]],\n",
      "\n",
      "         [[ 2.9151e-02]],\n",
      "\n",
      "         [[ 6.8702e-03]],\n",
      "\n",
      "         [[-3.5005e-02]],\n",
      "\n",
      "         [[ 7.0849e-02]],\n",
      "\n",
      "         [[ 6.2410e-02]],\n",
      "\n",
      "         [[-5.5762e-02]],\n",
      "\n",
      "         [[-1.4525e-02]],\n",
      "\n",
      "         [[ 1.5320e-01]],\n",
      "\n",
      "         [[-1.0891e-01]],\n",
      "\n",
      "         [[ 7.3283e-02]],\n",
      "\n",
      "         [[-9.5656e-04]],\n",
      "\n",
      "         [[-1.5681e-02]],\n",
      "\n",
      "         [[ 8.4110e-04]],\n",
      "\n",
      "         [[ 1.7365e-01]],\n",
      "\n",
      "         [[-7.3115e-02]],\n",
      "\n",
      "         [[-3.4541e-02]],\n",
      "\n",
      "         [[-3.7911e-02]],\n",
      "\n",
      "         [[-2.5482e-02]],\n",
      "\n",
      "         [[ 2.7152e-02]],\n",
      "\n",
      "         [[ 3.1801e-02]],\n",
      "\n",
      "         [[ 3.4108e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5876e-04]],\n",
      "\n",
      "         [[ 8.8861e-03]],\n",
      "\n",
      "         [[-7.7672e-04]],\n",
      "\n",
      "         [[-9.8488e-04]],\n",
      "\n",
      "         [[ 1.3420e-02]],\n",
      "\n",
      "         [[-2.4822e-03]],\n",
      "\n",
      "         [[-1.3488e-02]],\n",
      "\n",
      "         [[ 1.0678e-02]],\n",
      "\n",
      "         [[ 4.1617e-03]],\n",
      "\n",
      "         [[-2.6178e-02]],\n",
      "\n",
      "         [[-2.5867e-02]],\n",
      "\n",
      "         [[ 1.3985e-03]],\n",
      "\n",
      "         [[-5.5823e-03]],\n",
      "\n",
      "         [[ 1.2065e-02]],\n",
      "\n",
      "         [[ 5.8643e-03]],\n",
      "\n",
      "         [[ 1.0673e-03]],\n",
      "\n",
      "         [[-1.5103e-02]],\n",
      "\n",
      "         [[ 1.2000e-02]],\n",
      "\n",
      "         [[-2.6393e-03]],\n",
      "\n",
      "         [[ 5.8640e-03]],\n",
      "\n",
      "         [[ 2.2981e-02]],\n",
      "\n",
      "         [[ 4.7002e-04]],\n",
      "\n",
      "         [[ 7.8179e-03]],\n",
      "\n",
      "         [[ 1.1657e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1269e-02]],\n",
      "\n",
      "         [[-4.5641e-03]],\n",
      "\n",
      "         [[-1.3593e-02]],\n",
      "\n",
      "         [[ 5.7113e-03]],\n",
      "\n",
      "         [[-4.6884e-02]],\n",
      "\n",
      "         [[-1.2428e-02]],\n",
      "\n",
      "         [[-8.7864e-03]],\n",
      "\n",
      "         [[ 4.3334e-03]],\n",
      "\n",
      "         [[-9.8754e-03]],\n",
      "\n",
      "         [[ 1.1862e-02]],\n",
      "\n",
      "         [[ 1.9756e-02]],\n",
      "\n",
      "         [[ 5.5280e-02]],\n",
      "\n",
      "         [[-1.0633e-02]],\n",
      "\n",
      "         [[-1.1993e-03]],\n",
      "\n",
      "         [[ 4.0964e-03]],\n",
      "\n",
      "         [[-1.0020e-02]],\n",
      "\n",
      "         [[-2.3587e-02]],\n",
      "\n",
      "         [[ 1.3686e-02]],\n",
      "\n",
      "         [[-3.4760e-02]],\n",
      "\n",
      "         [[-7.1710e-03]],\n",
      "\n",
      "         [[ 1.9993e-02]],\n",
      "\n",
      "         [[ 1.2665e-03]],\n",
      "\n",
      "         [[ 5.3402e-02]],\n",
      "\n",
      "         [[-5.7458e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3185e-02]],\n",
      "\n",
      "         [[-1.4744e-03]],\n",
      "\n",
      "         [[ 1.2077e-04]],\n",
      "\n",
      "         [[ 4.8520e-03]],\n",
      "\n",
      "         [[ 8.5572e-03]],\n",
      "\n",
      "         [[-6.9985e-03]],\n",
      "\n",
      "         [[ 1.3290e-03]],\n",
      "\n",
      "         [[ 3.1599e-03]],\n",
      "\n",
      "         [[-9.2819e-04]],\n",
      "\n",
      "         [[ 9.0381e-04]],\n",
      "\n",
      "         [[-6.1338e-03]],\n",
      "\n",
      "         [[-4.6902e-04]],\n",
      "\n",
      "         [[ 6.6452e-03]],\n",
      "\n",
      "         [[-4.2547e-04]],\n",
      "\n",
      "         [[-1.0247e-02]],\n",
      "\n",
      "         [[ 9.8007e-03]],\n",
      "\n",
      "         [[-1.6697e-03]],\n",
      "\n",
      "         [[ 3.8887e-03]],\n",
      "\n",
      "         [[-7.7633e-03]],\n",
      "\n",
      "         [[ 2.7616e-03]],\n",
      "\n",
      "         [[ 4.9575e-03]],\n",
      "\n",
      "         [[-7.7899e-04]],\n",
      "\n",
      "         [[ 5.6463e-03]],\n",
      "\n",
      "         [[ 1.2729e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8796e-03]],\n",
      "\n",
      "         [[-2.4535e-02]],\n",
      "\n",
      "         [[-5.9820e-03]],\n",
      "\n",
      "         [[ 6.0537e-03]],\n",
      "\n",
      "         [[ 3.7369e-03]],\n",
      "\n",
      "         [[ 2.1650e-03]],\n",
      "\n",
      "         [[ 1.0215e-02]],\n",
      "\n",
      "         [[ 1.6344e-03]],\n",
      "\n",
      "         [[-1.3381e-03]],\n",
      "\n",
      "         [[-6.7522e-03]],\n",
      "\n",
      "         [[ 1.7109e-02]],\n",
      "\n",
      "         [[ 2.7187e-03]],\n",
      "\n",
      "         [[ 6.6776e-03]],\n",
      "\n",
      "         [[-1.0323e-03]],\n",
      "\n",
      "         [[-9.7842e-03]],\n",
      "\n",
      "         [[-6.0601e-03]],\n",
      "\n",
      "         [[ 8.5246e-03]],\n",
      "\n",
      "         [[ 2.8185e-03]],\n",
      "\n",
      "         [[ 1.3248e-03]],\n",
      "\n",
      "         [[ 2.3139e-03]],\n",
      "\n",
      "         [[-7.6426e-03]],\n",
      "\n",
      "         [[-2.8601e-03]],\n",
      "\n",
      "         [[-4.2652e-03]],\n",
      "\n",
      "         [[ 2.6605e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0706e-02]],\n",
      "\n",
      "         [[ 6.7720e-02]],\n",
      "\n",
      "         [[ 3.5703e-02]],\n",
      "\n",
      "         [[-1.6118e-02]],\n",
      "\n",
      "         [[-4.0691e-03]],\n",
      "\n",
      "         [[ 3.2254e-02]],\n",
      "\n",
      "         [[-5.2482e-02]],\n",
      "\n",
      "         [[-4.2509e-02]],\n",
      "\n",
      "         [[ 4.0365e-02]],\n",
      "\n",
      "         [[-2.5108e-02]],\n",
      "\n",
      "         [[-1.5236e-01]],\n",
      "\n",
      "         [[ 1.0364e-01]],\n",
      "\n",
      "         [[-6.6781e-02]],\n",
      "\n",
      "         [[ 7.2267e-03]],\n",
      "\n",
      "         [[ 1.3193e-02]],\n",
      "\n",
      "         [[-2.0022e-02]],\n",
      "\n",
      "         [[-1.5210e-01]],\n",
      "\n",
      "         [[ 7.1359e-02]],\n",
      "\n",
      "         [[ 3.2160e-02]],\n",
      "\n",
      "         [[ 3.0184e-02]],\n",
      "\n",
      "         [[ 1.9752e-02]],\n",
      "\n",
      "         [[-1.9903e-02]],\n",
      "\n",
      "         [[-5.1442e-02]],\n",
      "\n",
      "         [[-2.2311e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9895e-03]],\n",
      "\n",
      "         [[ 8.6324e-05]],\n",
      "\n",
      "         [[-5.8563e-03]],\n",
      "\n",
      "         [[-1.5521e-03]],\n",
      "\n",
      "         [[-6.1708e-03]],\n",
      "\n",
      "         [[-1.0817e-02]],\n",
      "\n",
      "         [[ 9.9105e-04]],\n",
      "\n",
      "         [[-8.6865e-03]],\n",
      "\n",
      "         [[-1.4622e-03]],\n",
      "\n",
      "         [[-7.4032e-04]],\n",
      "\n",
      "         [[-8.1127e-03]],\n",
      "\n",
      "         [[ 4.7822e-03]],\n",
      "\n",
      "         [[ 4.8283e-04]],\n",
      "\n",
      "         [[-5.9685e-03]],\n",
      "\n",
      "         [[-1.0455e-02]],\n",
      "\n",
      "         [[ 2.1845e-04]],\n",
      "\n",
      "         [[-9.8190e-03]],\n",
      "\n",
      "         [[-3.9328e-03]],\n",
      "\n",
      "         [[-1.9624e-02]],\n",
      "\n",
      "         [[-7.9629e-03]],\n",
      "\n",
      "         [[ 4.1535e-06]],\n",
      "\n",
      "         [[ 5.7963e-04]],\n",
      "\n",
      "         [[-8.1007e-03]],\n",
      "\n",
      "         [[ 4.0760e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1216e-02]],\n",
      "\n",
      "         [[-4.2114e-02]],\n",
      "\n",
      "         [[-9.4299e-03]],\n",
      "\n",
      "         [[-4.2683e-02]],\n",
      "\n",
      "         [[ 4.5870e-03]],\n",
      "\n",
      "         [[ 4.3511e-02]],\n",
      "\n",
      "         [[ 4.2425e-02]],\n",
      "\n",
      "         [[ 8.3840e-03]],\n",
      "\n",
      "         [[ 3.4029e-03]],\n",
      "\n",
      "         [[-9.1650e-03]],\n",
      "\n",
      "         [[ 3.5595e-02]],\n",
      "\n",
      "         [[-3.3011e-02]],\n",
      "\n",
      "         [[-1.2902e-02]],\n",
      "\n",
      "         [[ 7.3328e-03]],\n",
      "\n",
      "         [[-2.1481e-03]],\n",
      "\n",
      "         [[-9.0925e-03]],\n",
      "\n",
      "         [[-4.4348e-02]],\n",
      "\n",
      "         [[-1.3154e-01]],\n",
      "\n",
      "         [[-3.2679e-02]],\n",
      "\n",
      "         [[-6.2628e-03]],\n",
      "\n",
      "         [[-3.7620e-02]],\n",
      "\n",
      "         [[-1.5534e-02]],\n",
      "\n",
      "         [[-6.9545e-02]],\n",
      "\n",
      "         [[-6.4345e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3868e-04]],\n",
      "\n",
      "         [[-8.3552e-04]],\n",
      "\n",
      "         [[-3.8010e-04]],\n",
      "\n",
      "         [[ 2.6487e-03]],\n",
      "\n",
      "         [[ 5.2007e-04]],\n",
      "\n",
      "         [[-2.3702e-03]],\n",
      "\n",
      "         [[-1.0137e-03]],\n",
      "\n",
      "         [[ 5.1695e-04]],\n",
      "\n",
      "         [[ 6.7759e-04]],\n",
      "\n",
      "         [[ 1.3587e-02]],\n",
      "\n",
      "         [[ 3.2372e-03]],\n",
      "\n",
      "         [[-3.0830e-03]],\n",
      "\n",
      "         [[ 8.3146e-04]],\n",
      "\n",
      "         [[ 9.1677e-04]],\n",
      "\n",
      "         [[-1.2559e-04]],\n",
      "\n",
      "         [[ 2.8383e-04]],\n",
      "\n",
      "         [[-1.5854e-03]],\n",
      "\n",
      "         [[ 6.4957e-04]],\n",
      "\n",
      "         [[ 6.4755e-03]],\n",
      "\n",
      "         [[ 2.4884e-03]],\n",
      "\n",
      "         [[ 7.5190e-03]],\n",
      "\n",
      "         [[-7.6645e-04]],\n",
      "\n",
      "         [[ 3.3907e-03]],\n",
      "\n",
      "         [[ 1.9508e-03]]]], device='cuda:0')}, 36: {'momentum_buffer': tensor([ 0.0069,  0.0011, -0.0014,  0.1290,  0.0186, -0.0152,  0.0126,  0.0045,\n",
      "        -0.0930,  0.0030, -0.0691,  0.0030], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.001, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]}]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# 옵티마이저의 state_dict 출력\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5663766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.2024e-01, -1.1133e+00,  1.8146e-05,  1.9074e-02,  1.0009e+00,\n",
      "        -1.8399e+00, -1.6432e-02,  1.2515e-03,  4.3600e-04, -3.7923e-01,\n",
      "        -1.5488e+00, -1.8192e-04, -1.5520e+00, -3.5521e+00, -1.4881e+00,\n",
      "         3.1239e+00], device='cuda:0')\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['cnn_head.1.running_mean'])\n",
    "print(model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "423d3128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\synnc\\AppData\\Local\\Temp\\ipykernel_19132\\372643628.py:221: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert h % self.spec_groups == 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m dummy_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m61\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\onnx\\utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[0;32m    190\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[38;5;28mbool\u001b[39m, Collection[Type[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\onnx\\utils.py:1548\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1546\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[1;32m-> 1548\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1563\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[0;32m   1564\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\onnx\\utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m   1112\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[1;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\onnx\\utils.py:989\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    984\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[0;32m    985\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     )\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m    991\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\onnx\\utils.py:893\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    891\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[0;32m    892\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 893\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[0;32m    902\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\jit\\_trace.py:1268\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m   1267\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m-> 1268\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\jit\\_trace.py:127\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[1;32m--> 127\u001b[0m graph, out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\jit\\_trace.py:118\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[0;32m    117\u001b[0m     inputs_states\u001b[38;5;241m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[1;32m--> 118\u001b[0m outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[0;32m    120\u001b[0m     inputs_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (inputs_states[\u001b[38;5;241m0\u001b[39m], trace_inputs)\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[1;32mIn[12], line 191\u001b[0m, in \u001b[0;36mBCResNets.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, num_modules \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn):\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_modules):\n\u001b[1;32m--> 191\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCBlocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n\u001b[0;32m    193\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[1;32mIn[12], line 117\u001b[0m, in \u001b[0;36mBCResBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# 2D part\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m--> 117\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     aux_2d_res \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_gpool(x)\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[1;32mIn[12], line 68\u001b[0m, in \u001b[0;36mConvBNReLU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\synnc\\miniconda3\\envs\\kws\\lib\\site-packages\\torch\\nn\\modules\\module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[1;32mIn[12], line 221\u001b[0m, in \u001b[0;36mSubSpectralNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    219\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    220\u001b[0m b, c, h, w \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m h \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec_groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    222\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(b, c \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec_groups, h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec_groups, w) \n\u001b[0;32m    223\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssnorm(x)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "dummy_data = torch.empty(1, 1, 40, 61, dtype = torch.float32).to('cuda')\n",
    "torch.onnx.export(model, dummy_data, \"output.onnx\", export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(model(sp_transform(waveform).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ec02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utterance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
